---
title: "light_activity_2d_classification"
author: "Carolina Guidolin"
date: "2025-01-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Aim
We want to understand if combining light (mEDI) and activity (PIM) could help to imporve the algorithm's performance

## First step: identify observations which are classified as clusters of both light and activity 
```{r}
# We use the inputs which we know to lead to the best classification for mEDI
medi_thr = 1
min_length = 60
max_int = 0

# Identify clusters
medi_clusters <- df.LL.nosleep %>%
    ungroup() %>%
    mutate(low_medi = MEDI < medi_thr) %>%
    nest_by(Id) %>%
    mutate(
      data = list(
        data_find_clusters(
          data, 
          low_medi, 
          min_length = min_length, 
          max_interrupt = max_int,
          cluster_name = "low_medi_cluster"
        )
      )
    ) %>%
    unnest(cols = data) %>%
    ungroup()

# Now we detect clusters of PIM using inputs which we know work best
## Note that we apply the data_find_cluster function not to the raw dataset (df.LL.nosleep) but to the medi_cluster dataset, so that we end up with a df that contains both identified clusters of low_pim and low_medi
pim_thr = 5
min_length = 54
max_int = 0
  
pim_clusters <- medi_clusters %>%
    ungroup() %>%
    mutate(low_pim = PIM < pim_thr) %>%
    nest_by(Id) %>%
    mutate(
      data = list(
        data_find_clusters(
          data, 
          low_pim, 
          min_length = min_length, 
          max_interrupt = max_int,
          cluster_name = "low_pim_cluster"
        )
      )
    ) %>%
    unnest(cols = data) %>%
    ungroup()

# We need to apply some re-coding to the data
# When State is on, it should have a value of 1
# When State is off, it should have a value of 0 
# When low_medi cluster = TRUE, it should be coded as 0, else as 1
# When low_pim cluster = TRUE, it should be coded as 0, else as 1
clusters_clean <- pim_clusters %>%
  select(Id, Datetime, State, is_low_medi_cluster, is_low_pim_cluster, low_pim, low_medi, MEDI, PIM, bag) %>%
  mutate(
    State = case_when(
      State == "on" ~ 1, 
      State == "off" ~ 0,
      is.na(State) ~ NA_real_), # keep sleep states as NA,
    is_low_medi_cluster = case_when(
      is.na(is_low_medi_cluster) ~ NA_real_, # Propagate NA from low_var to cluster_col, this is useful when applying the algorithm to a rolled df where NAs are present
      is_low_medi_cluster == TRUE ~ 0,
      is_low_medi_cluster == FALSE ~ 1
    ),
    is_low_pim_cluster = case_when(
      is.na(is_low_pim_cluster) ~ NA_real_,  # Propagate NA from low_var to cluster_col, this is useful when applying the algorithm to a rolled df where NAs are present
      is_low_pim_cluster == TRUE ~ 0,
      is_low_pim_cluster == FALSE ~ 1
    ))
  
```

# Building a PR curve based on agreement between cluters of low activity and clusters of low light
In cases of disagreement, we assign a NA value to the classification output
```{r}
 #We want to build a precision recall curve for our classifier algorithm, which, based o our "Ground truth", i.e. the wear log state values (on = 1 and off = 0), classifies the performance of our algorithm for detecting non-wear as follows:
  #1) State = 0, cluster medi = 0, cluster pim = 0 -> true positive
  #2) State = 0, cluster medi= 1, cluster pim = 1 -> false negative
  #3) State = 1, cluster medi = 0, cluster pim =  0 -> false positive
  #4) State = 1, cluster medi = 1, cluster pim = 1 -> true negative
  
# This approach handles disagreement by assigning a NA value to observations were the algorithm identifies a cluster of low activity but no cluster of low medi, and viceversa
clusters_clean_2 <- clusters_clean %>%
    mutate(classification = case_when(
      State == 0 & is_low_medi_cluster == 0 & is_low_pim_cluster == 0 ~ "TP",
      State == 0 & is_low_medi_cluster == 1 & is_low_pim_cluster == 1 ~ "FN",
      State == 1 & is_low_medi_cluster == 0 & is_low_pim_cluster == 0 ~ "FP",
      State == 1 & is_low_medi_cluster == 1 & is_low_pim_cluster == 1 ~ "TN",
      .default = NA_character_))

prc <- clusters_clean_2 %>%
    group_by(classification) %>% #!! if you want to visualise individual PRC, then you have to group_by(Id, classification). Else, only group_by(classification)
    summarise(count = n()) %>%
    pivot_wider(names_from = classification, values_from = count, values_fill = list(count=0)) %>%
    mutate(TPR = TP/(TP+FN), #true positive rate
           FPR = FP/(FP+TN), #false positive rate
           PPV = TP/(TP+FP), #positive predictive value
           NPV = TN/(FN+TN)) %>% #negative predictive value 
  mutate(f1_score = (2* PPV * TPR)/(PPV + TPR))
```

### What does this tell us?
We get a f1 score of 0.8468508, hich is pretty good. However, we cannot compare this directly to the f1 score obtained by looking at clusters of low pim or clusters of low medi, because of the difference in NA values. In fact, the n of observations where there is a disagreement between the two values is 107640. This corresponds to approx. 11.2% of the data (excluding State = NA for sleep periods; this was calculated as 1513786 [tot obs] - 559650 [sleep obs] = 954136. Then, 107640/954136 * 100 = 11.28). This also means that for the observations which are not sleep periods (State = NA), 88.7% of them show agreement between medi and pim clusters. 

## Handling disagreement between clusters of low medi and clusters of low pim  
### Approach 1
We handle disagreement between cluster medi and cluster pim by prioritising cluster medi detection 
```{r}
# This approach handles disagreement by weighing clusters of low medi more

clusters_medi_priority <- clusters_clean %>%
    mutate(classification = case_when(
      State == 0 & is_low_medi_cluster == 0 & is_low_pim_cluster == 0 ~ "TP",
      State == 0 & is_low_medi_cluster == 1 & is_low_pim_cluster == 1 ~ "FN",
      State == 1 & is_low_medi_cluster == 0 & is_low_pim_cluster == 0 ~ "FP",
      State == 1 & is_low_medi_cluster == 1 & is_low_pim_cluster == 1 ~ "TN",
      State == 0 & (is_low_medi_cluster != is_low_pim_cluster) ~ if_else(is_low_medi_cluster == 0, "TP", "FN"),
      State == 1 & (is_low_medi_cluster != is_low_pim_cluster) ~ if_else(is_low_medi_cluster == 0, "FP", "TN"),
      .default = NA_character_))

prc_medi_priority <- clusters_medi_priority %>%
    group_by(classification) %>% #!! if you want to visualise individual PRC, then you have to group_by(Id, classification). Else, only group_by(classification)
    summarise(count = n()) %>%
    pivot_wider(names_from = classification, values_from = count, values_fill = list(count=0)) %>%
    mutate(TPR = TP/(TP+FN), #true positive rate
           FPR = FP/(FP+TN), #false positive rate
           PPV = TP/(TP+FP), #positive predictive value
           NPV = TN/(FN+TN)) %>% #negative predictive value 
  mutate(f1_score = (2* PPV * TPR)/(PPV + TPR))
```

### Approach 2
We handle disagreement between cluster medi and cluster pim by prioritising cluster pim detection 
```{r}
# This approach handles disagreement by weighing clusters of low pim more

clusters_pim_priority <- clusters_clean %>%
    mutate(classification = case_when(
      State == 0 & is_low_medi_cluster == 0 & is_low_pim_cluster == 0 ~ "TP",
      State == 0 & is_low_medi_cluster == 1 & is_low_pim_cluster == 1 ~ "FN",
      State == 1 & is_low_medi_cluster == 0 & is_low_pim_cluster == 0 ~ "FP",
      State == 1 & is_low_medi_cluster == 1 & is_low_pim_cluster == 1 ~ "TN",
      State == 0 & (is_low_medi_cluster != is_low_pim_cluster) ~ if_else(is_low_pim_cluster == 0, "TP", "FN"),
      State == 1 & (is_low_medi_cluster != is_low_pim_cluster) ~ if_else(is_low_pim_cluster == 0, "FP", "TN"),
      .default = NA_character_))

prc_pim_priority <- clusters_pim_priority %>%
    group_by(classification) %>% #!! if you want to visualise individual PRC, then you have to group_by(Id, classification). Else, only group_by(classification)
    summarise(count = n()) %>%
    pivot_wider(names_from = classification, values_from = count, values_fill = list(count=0)) %>%
    mutate(TPR = TP/(TP+FN), #true positive rate
           FPR = FP/(FP+TN), #false positive rate
           PPV = TP/(TP+FP), #positive predictive value
           NPV = TN/(FN+TN)) %>% #negative predictive value 
  mutate(f1_score = (2* PPV * TPR)/(PPV + TPR))
```

### Approach 3
Since the previous two approaches seem rather arbitrary, we decide to handle disagreement based on bag use. More specifically, in a situation where the algorithm has identified a cluster of low medi but not a cluster of low pim, we consult the bag column:
- If the bag was not used (bag = 0), we rely on PIM
- If the bag was used (bag = 1), we rely on mEDI
```{r}
clusters_bag <- clusters_clean %>%
  mutate(classification = case_when(
    State == 0 & is_low_medi_cluster == 0 & is_low_pim_cluster == 0 ~ "TP",
    State == 0 & is_low_medi_cluster == 1 & is_low_pim_cluster == 1 ~ "FN",
    State == 1 & is_low_medi_cluster == 0 & is_low_pim_cluster == 0 ~ "FP",
    State == 1 & is_low_medi_cluster == 1 & is_low_pim_cluster == 1 ~ "TN",
    
    # Handle disagreements based on the bag column
    State == 0 & is_low_medi_cluster != is_low_pim_cluster ~ if_else(
      bag == 0, # bag not being used
      if_else(is_low_pim_cluster == 0, "TP", "FN"),  # hence, we trust pim 
      if_else(is_low_medi_cluster == 0, "TP", "FN")  # else (bag = 1, so it's being used, we trust medi)
    ),
    State == 1 & (is_low_medi_cluster != is_low_pim_cluster) ~ if_else(is_low_medi_cluster == 0, "FP", "TN"), #since the glasses are on we can't rely on the bag 
    TRUE ~ NA_character_  # Handle any other cases or missing values for State
  ))

prc_bag_priority <- clusters_bag %>%
    group_by(classification) %>% #!! if you want to visualise individual PRC, then you have to group_by(Id, classification). Else, only group_by(classification)
    summarise(count = n()) %>%
    pivot_wider(names_from = classification, values_from = count, values_fill = list(count=0)) %>%
    mutate(TPR = TP/(TP+FN), #true positive rate
           FPR = FP/(FP+TN), #false positive rate
           PPV = TP/(TP+FP), #positive predictive value
           NPV = TN/(FN+TN)) %>% #negative predictive value 
  mutate(f1_score = (2* PPV * TPR)/(PPV + TPR))
```

### What does this tell us? 
Weighing mEDI clusters and PIM clusters (approach #1 and #2) arbitrarily leads to the same f1 scores as only looking at one cluster. In other words: weighing mEDI clusters in case of disagreements leads to a classifier performance that is equivalent to only considering mEDI clusters and excluding pim clusters; and weighing pim clusters in case of disagreements leads to a classifier performance that is equivalent to only considering pim clusters and excluding medi clusters. This suggests that this might not be an useful strategy. On the other hand, handling disagreements based on bag use leads to an algorithm performance of f1 = 0.78, which is slightly higher than only considering clusters of low light alone. 

### Alternative approach
What if the reliance on the use of the bag was actually weighted more by including it in the classification of not just the disagreement cases, but also the agreement cases?
```{r}
# Think about the agreement cases first:

## Off cases  
  #1) If State = off and bag = 1 (used), then if cluster medi = TRUE -> true positive
  #2) If State = off and bag = 1 (used), then if cluster medi = FALSE -> false negative
  #3) If State = off and bag = 0 (not used), then if cluster pim = TRUE -> true positive
  #4) If State = off and bag = 0 (not used), then if cluster pim = FALSE -> false negative
  
## On cases and agreement
  #5) If State = on and both cluster medi and cluster pim = TRUE -> false positive 
  #6) If State = on, and both cluster medi and cluster pim = FALSE -> true negative 

## On cases and disagreement -> prioritise mEDI clusters
  #7) If State = on, and cluster medi = TRUE but cluster pim = FALSE, prioritise cluster medi -> false positive  
  #8) If State = on, and cluster medi = FALSE but cluster pim = TRUE, prioritise cluster medi -> true negative

clusters_state_bag <- clusters_clean %>%
  mutate(classification = case_when(
    # Off cases 
    State == 0 & bag == 1 ~ if_else(is_low_medi_cluster == 0, "TP", "FN"), # cases 1) and 2)
    State == 0 & bag == 0 ~ if_else(is_low_pim_cluster == 0, "TP", "FN"), # cases 3) and 4) 
    
    # On cases and agreement of medi and pim
    State == 1 & is_low_medi_cluster == 0 & is_low_pim_cluster == 0 ~ "FP", # case 5)
    State == 1 & is_low_medi_cluster == 1 & is_low_pim_cluster == 1 ~ "TN", # case 6)
    
    # On cases with disagreement
    State == 1 & is_low_medi_cluster != is_low_pim_cluster ~ if_else(
      is_low_medi_cluster == 0, "FP", "TN" # cases 7 and 8 
    ),
    
    .default = NA_character_))

prc_1 <- clusters_state_bag %>%
    group_by(classification) %>% #!! if you want to visualise individual PRC, then you have to group_by(Id, classification). Else, only group_by(classification)
    summarise(count = n()) %>%
    pivot_wider(names_from = classification, values_from = count, values_fill = list(count=0)) %>%
    mutate(TPR = TP/(TP+FN), #true positive rate
           FPR = FP/(FP+TN), #false positive rate
           PPV = TP/(TP+FP), #positive predictive value
           NPV = TN/(FN+TN)) %>% #negative predictive value 
  mutate(f1_score = (2* PPV * TPR)/(PPV + TPR))
```

### What does this tell us?
The results are identical to including the bag only in disagreement cases, i.e. F1 = 0.78. 