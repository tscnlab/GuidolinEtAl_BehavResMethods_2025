---
title: "metrics_stats"
author: "Carolina Guidolin"
date: "2024-12-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Aim
To calculate differences between metrics calculated in the script metrics_comparison.Rmd. Specifically, we will be using a t-test to do this.

## Let's first check the normality of our data
Import the function norm_check before running this. The function is contained in the norm_check_fun.R script.
```{r}
# Create a list of the dfs containing the metrics 
metrics_dfs <- list(mlit250_all, mlit1000_all, llit10_all, llit250_all, llit1000_all, flit10_all, flit250_all, flit1000_all, tat1000_all, tat250_all)

# Visualise normality of the means for each df

for (df in metrics_dfs) {

    print(norm_check_means(df))
  
}

## The distribution looks more or less normal, and we can proceed with a paired t-test on the means

# Checking the normality of the deltas
for (df in metrics_dfs) {

    print(norm_check_deltas(df))
  
}

## The deltas are not normally distributed, hence we cannot run a t-test but rather a sign-test

```
### Performing the paired sample Student t-test
#### First, we  create a function to perform the t-test for all metrics
```{r}
# T-test for the means
## First, we create a function for the metrics that have been calculated as average of 6 participation days
## These are: mlit250, mlit1000, llit10, llit250, llit1000, flit10, flit250, flit1000, tat1000, tat250
ttest_means <- function (df) {
  
  # Get the name of the input df as a string
  df_name <- deparse(substitute(df))
  
# Turning df into long form to perform computations
  df_long <- df %>%
  pivot_longer(cols = c(mean_raw, mean_wrlg, mean_clusters),
               names_to = "dataset",
               values_to = "mean")
  
  # Turn mean column to numeric (seconds)
    df_long <- df_long %>%
    mutate(mean = as.numeric(mean))
  
    # Performing t-test
  t_test <- df_long %>%
    rstatix::t_test(mean ~ dataset, paired = TRUE) %>%
    rstatix::add_significance()
  
  # Adding a column indicating which metric the t-test corresponds
  t_test$metric <- (df_name)
  
 # Assigning dfs to dynamically named variables in the global environment
  assign(paste0(df_name, "_long"), df_long, envir = .GlobalEnv)
  assign(paste0("t_test_", df_name), t_test, envir = .GlobalEnv)

}    


## For the two remaining metrics (IS and IV), we are calculating t-test staistics separately


```

#### Applying the function to the metrics dfs
```{r}

#MLiT250
ttest_means(mlit250_all)

# MLiT1000
ttest_means(mlit1000_all)

# FLitT 10
ttest_means(flit10_all)

#FLitT250
ttest_means(flit250_all)

#FLiT1000
ttest_means(flit1000_all)

# LLitT 10
ttest_means(llit10_all)

# LLitT 250
ttest_means(llit250_all)

# LLitT 1000
ttest_means(llit1000_all)

# TAT 250
ttest_means(tat250_all)

# TAT 1000
ttest_means(tat1000_all)


```

### Peform t-test on remaining metrics (IV and IS)
```{r}
# Turning into long format
iv_means_long <- iv_all %>%
  pivot_longer(cols = c(IV_raw, IV_wrlg, IV_clusters),
               names_to = "dataset",
               values_to = "mean") 

is_means_long <- is_all %>%
  pivot_longer(cols = c(IS_raw, IS_wrlg, IS_clusters),
               names_to = "dataset",
               values_to = "mean")

# Performing the t-test
iv_ttest <- iv_means_long %>%
    rstatix::t_test(mean ~ dataset, paired = TRUE) %>%
    rstatix::add_significance() %>%
  mutate(metric = "iv")

is_ttest <- is_means_long %>%
    rstatix::t_test(mean ~ dataset, paired = TRUE) %>%
    rstatix::add_significance() %>%
  mutate(metric = "is")

#Combining all dfs into one
ttest_all <- dplyr::bind_rows(t_test_mlit1000_all,
                              t_test_mlit250_all,
                              t_test_flit10_all,
                              t_test_flit1000_all,
                              t_test_flit250_all,
                              t_test_llit10_all,
                              t_test_llit250_all,
                              t_test_llit1000_all,
                              t_test_tat250_all,
                              t_test_tat1000_all,
                              iv_ttest,
                              is_ttest)
```

### Investigating differences in the delta using a sign test
First, we need to write a function for this 
```{r}
# Sign-test for the deltas
signtest_deltas <- function (df) {
  
  # Get the name of the input df as a string
  df_name <- deparse(substitute(df))
  
# Turning df into long form to perform computations
  df_long <- df %>%
  pivot_longer(cols = c(delta_wrlg, delta_clusters),
               names_to = "metric",
               values_to = "delta")
  
  # Turn mean column to numeric (minutes)
    df_long <- df_long %>%
    mutate(delta = as.numeric(delta)/60) #turning the deltas into mins, this is optional (could keep them in secs)
  
    # Performing t-test
  signtest <- df_long %>%
    rstatix::sign_test(delta ~ metric) %>%
    rstatix::add_significance()
  
  # Adding a column indicating which metric the t-test corresponds
  signtest$metric <- (df_name)
  
 # Assigning dfs to dynamically named variables in the global environment
  assign(paste0(df_name, "_delta_long"), df_long, envir = .GlobalEnv)
  assign(paste0("signtest_", df_name), signtest, envir = .GlobalEnv)

}    

```

#### Run the sign test to all dfs (iv and is included, as the df structure enables this)
```{r}

#MLiT250
signtest_deltas(mlit250_all)

# MLiT1000
signtest_deltas(mlit1000_all)

# FLitT 10
signtest_deltas(flit10_all)

#FLitT250
signtest_deltas(flit250_all)

#FLiT1000
signtest_deltas(flit1000_all)

# LLitT 10
signtest_deltas(llit10_all)

# LLitT 250
signtest_deltas(llit250_all)

# LLitT 1000
signtest_deltas(llit1000_all)

# TAT 250
signtest_deltas(tat250_all)

# TAT 1000
signtest_deltas(tat1000_all)

# IV
signtest_deltas(iv_all)

# IS
signtest_deltas(is_all)

#Combining all dfs into one
signest_all <- dplyr::bind_rows(signtest_mlit1000_all,
                              signtest_mlit250_all,
                              signtest_flit10_all,
                              signtest_flit1000_all,
                              signtest_flit250_all,
                              signtest_llit10_all,
                              signtest_llit250_all,
                              signtest_llit1000_all,
                              signtest_tat250_all,
                              signtest_tat1000_all,
                              signtest_is_all,
                              signtest_iv_all)
```

### Investigating the significant differences
In the t-tests above, we observe a significance difference in the metrics TAT 250 and TAT 1000 when calculated in the raw dataset, wear log dataset and clusters dataset. Next, we want to know: does this correlate with the compliance in using the black bag? We have this information from the bag_activity_prc script in the variable per_bag_use. Below is a repetition of how that was calculated
```{r}
 bag_use <- df.LL.nosleep %>%
  group_by(Id) %>%
   mutate(bag_use = case_when(
     State == "off" & bag == 0 ~ "notused", #when State is off and bag is 0, it was not used
     State == "off" & bag == 1 ~ "used", #when state is off and bag is 1, it was used
     .default = NA_character_)) %>%
  ungroup()

per_bag_use <- bag_use %>%
  group_by(Id, bag_use) %>% 
  summarise(count = n()) %>% #calculating how many used and notused per participant
  filter(!is.na(bag_use)) %>% #eliminate NAs which correspond to when State is on or sleep
  complete(bag_use = c("used", "notused"), fill = list(count = 0)) %>% #if participant does not have values for "used" or "notused" because they either never used the bag, or always used it, we replace that with 0
  mutate(total = sum(count), #counting total entries per participant
         compliance_per = if_else(bag_use == "used", (count*100)/total, NA), #calculating % of "used" over total entries
         compliance_per = round(compliance_per, 1)) %>% #rounding the percentage value to 1 decimal point
  filter(!is.na(compliance_per)) #eliminate the NA that comes from the ifelse

```

#### Combining per_bag_use with the TAT dfs
```{r}
# Turning deltas into long form to perform computations
  tat250_deltas_long <- tat250_all %>%
  pivot_longer(cols = c(delta_wrlg, delta_clusters),
               names_to = "metric",
               values_to = "delta")

# Merging the bag use info 
tat250_deltas_long <- tat250_deltas_long %>%
  left_join(per_bag_use, by = "Id")

# Plotting



ggplot(tat250_deltas_long, aes(x = as.numeric(delta), y = compliance_per, colour = metric)) +
    geom_jitter() +
    scale_x_continuous(breaks = c(0 , -250, -500, -750),
                       labels = function(x) sprintf("%.2f mins", x / 60)) + # Format with 2 decimal places 
    labs(x = "Delta TAT 250", y = "Percentage bag use (%)", title = "TAT 250 lx") +
    theme_bw() +
    theme(aspect.ratio = 1)
  
```
# Do the same for TAT 1000
```{r}
# Turning deltas into long form to perform computations
  tat1000_deltas_long <- tat1000_all %>%
  pivot_longer(cols = c(delta_wrlg, delta_clusters),
               names_to = "metric",
               values_to = "delta")

# Merging the bag use info 
tat1000_deltas_long <- tat1000_deltas_long %>%
  left_join(per_bag_use, by = "Id")

# Plotting

ggplot(tat1000_deltas_long, aes(x = as.numeric(delta), y = compliance_per, colour = metric)) +
    geom_jitter() +
    scale_x_continuous(breaks = c(0 , -250, -500, -750),
                       labels = function(x) sprintf("%.2f mins", x / 60)) + # Format with 2 decimal places 
    labs(x = "Delta TAT 1000", y = "Percentage bag use (%)", title = "TAT 1000 lx") +
    theme_bw() +
    theme(aspect.ratio = 1)
```

