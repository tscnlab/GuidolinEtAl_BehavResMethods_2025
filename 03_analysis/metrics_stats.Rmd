---
title: "metrics_stats"
author: "Carolina Guidolin"
date: "2024-12-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Aim
To calculate differences between metrics calculated in the script metrics_comparison.Rmd. Specifically, we will be using a t-test to do this.

## Let's first check the normality of our data
Import the function norm_check before running this. The function is contained in the norm_check_fun.R script.
```{r}
# Create a list of the dfs containing the metrics 
metrics_dfs <- list(mlit250_all, mlit1000_all, llit10_all, llit250_all, llit1000_all, flit10_all, flit250_all, flit1000_all, tat1000_all, tat250_all)

# Visualise normality of the means for each df

for (df in metrics_dfs) {

    print(norm_check_means(df))
  
}

## The distribution looks more or less normal, and we can proceed with a paired t-test on the means

# Checking the normality of the deltas
for (df in metrics_dfs) {

    print(norm_check_deltas(df))
  
}

## The deltas are not normally distributed, hence we cannot run a t-test but rather a sign-test

```
### Performing the paired sample Student t-test
#### First, we  create a function to perform the t-test for all metrics
```{r}
# T-test for the means
## First, we create a function for the metrics that have been calculated as average of 6 participation days
## These are: mlit250, mlit1000, llit10, llit250, llit1000, flit10, flit250, flit1000, tat1000, tat250

ttest_means <- function (df) {
  
  # Get the name of the input df as a string
  df_name <- deparse(substitute(df))
  
# Turning df into long form to perform computations
  df_long <- df %>%
  pivot_longer(cols = c(mean_raw, mean_wrlg, mean_clusters),
               names_to = "dataset",
               values_to = "mean")
  
  # Turn mean column to numeric (seconds)
    df_long <- df_long %>%
    mutate(mean = as.numeric(mean))
  
    # Performing t-test
  t_test <- df_long %>%
    rstatix::t_test(mean ~ dataset, paired = TRUE) %>%
    rstatix::add_significance("p") %>%
    select(-c(p.adj, p.adj.signif))
  
 # Computing Cohen's D
  cohens_d <- df_long %>%
    rstatix::cohens_d(mean ~ dataset, paired = TRUE)
  
  # Merging Cohen's D into t-test results
  t_test <- t_test %>%
    mutate(cohens_d = cohens_d$effsize)  # Add Cohen's D as a new column
  
  # Adding a column indicating which metric the t-test corresponds
  t_test$metric <- (df_name)
  
  return(t_test)
  
}    

## For the two remaining metrics (IS and IV), we are calculating t-test staistics separately


```

#### Applying the function to the metrics dfs
```{r}

#MLiT250
mlit250_ttest <- ttest_means(mlit250_all)

# MLiT1000
mlit1000_ttest <- ttest_means(mlit1000_all)

# FLitT 10
flit10_ttest <- ttest_means(flit10_all)

#FLitT250
flit250_ttest <- ttest_means(flit250_all)

#FLiT1000
flit1000_ttest <- ttest_means(flit1000_all)

# LLitT 10
llit10_ttest <- ttest_means(llit10_all)

# LLitT 250
llit250_ttest <- ttest_means(llit250_all)

# LLitT 1000
llit1000_ttest <- ttest_means(llit1000_all)

# TAT 250
tat250_ttest <- ttest_means(tat250_all)

# TAT 1000
tat1000_ttest <- ttest_means(tat1000_all)


```

### Peform t-test on remaining metrics (IV and IS)
```{r}
# Turning into long format
iv_means_long <- iv_all %>%
  pivot_longer(cols = c(IV_raw, IV_wrlg, IV_clusters),
               names_to = "dataset",
               values_to = "mean") 

is_means_long <- is_all %>%
  pivot_longer(cols = c(IS_raw, IS_wrlg, IS_clusters),
               names_to = "dataset",
               values_to = "mean")

# Performing the t-test
iv_ttest <- iv_means_long %>%
    rstatix::t_test(mean ~ dataset, paired = TRUE) %>%
    mutate(metric = "iv") %>%
    rstatix::add_significance("p") %>%
    select(-c(p.adj, p.adj.signif))

is_ttest <- is_means_long %>%
    rstatix::t_test(mean ~ dataset, paired = TRUE)  %>%
    mutate(metric = "is") %>%
    rstatix::add_significance("p") %>%
    select(-c(p.adj, p.adj.signif)) 
  

cohens_d_iv <- iv_means_long %>%
  rstatix::cohens_d(mean ~ dataset, paired = TRUE)

cohens_d_is <- is_means_long %>%
    rstatix::cohens_d(mean ~ dataset, paired = TRUE)

iv_ttest <- iv_ttest %>%
    mutate(cohens_d = cohens_d_iv$effsize)  # Add Cohen's D as a new column
 
is_ttest <- is_ttest %>%
    mutate(cohens_d = cohens_d_is$effsize)  # Add Cohen's D as a new column
 
  


#Combining all dfs into one
ttest_all <- dplyr::bind_rows(mlit250_ttest,
                              mlit1000_ttest,
                              flit10_ttest,
                              flit250_ttest,
                              flit1000_ttest,
                              llit10_ttest,
                              llit250_ttest,
                              llit1000_ttest,
                              tat250_ttest,
                              tat1000_ttest,
                              iv_ttest,
                              is_ttest)

# Apply multiple corrections

ttest_final <- ttest_all %>% 
  mutate(p.adj = stats::p.adjust(p,
                           "fdr", # we choose FDR (or BH - same thing) as method
                           n=length(p))) %>% # we want to correct for all comparisons, i.e. n=36
  rstatix::add_significance("p.adj") %>%
  dplyr::relocate(metric, .before= .y.) # re-order columns

```

### Investigating differences in the delta using a sign test
First, we need to write a function for this 
```{r}
# Sign-test for the deltas
signtest_deltas <- function (df) {
  
  # Get the name of the input df as a string
  df_name <- deparse(substitute(df))
  
# Turning df into long form to perform computations
  df_long <- df %>%
  pivot_longer(cols = c(delta_wrlg, delta_clusters),
               names_to = "metric",
               values_to = "delta")
  
  # Turn mean column to numeric (minutes)
    df_long <- df_long %>%
    mutate(delta = as.numeric(delta)/60) #turning the deltas into mins, this is optional (could keep them in secs)
  
    # Performing t-test
  signtest <- df_long %>%
    rstatix::sign_test(delta ~ metric) %>%
    rstatix::add_significance("p")
  
  # Adding a column indicating which metric the t-test corresponds
  signtest$metric <- (df_name)
  
   # Computing Cohen's D
  cohens_d <- df_long %>%
    rstatix::cohens_d(delta ~ metric)
  
  # Merging Cohen's D into t-test results
  signtest <- signtest %>%
    mutate(cohens_d = cohens_d$effsize)  # Add Cohen's D as a new column
  
 # Assigning dfs to dynamically named variables in the global environment
  assign(paste0(df_name, "_delta_long"), df_long, envir = .GlobalEnv)
  assign(paste0("signtest_", df_name), signtest, envir = .GlobalEnv)

}    

```

#### Run the sign test to all dfs (iv and is included, as the df structure enables this)
```{r}

#MLiT250
signtest_deltas(mlit250_all)

# MLiT1000
signtest_deltas(mlit1000_all)

# FLitT 10
signtest_deltas(flit10_all)

#FLitT250
signtest_deltas(flit250_all)

#FLiT1000
signtest_deltas(flit1000_all)

# LLitT 10
signtest_deltas(llit10_all)

# LLitT 250
signtest_deltas(llit250_all)

# LLitT 1000
signtest_deltas(llit1000_all)

# TAT 250
signtest_deltas(tat250_all)

# TAT 1000
signtest_deltas(tat1000_all)

# IV
signtest_deltas(iv_all)

# IS
signtest_deltas(is_all)

#Combining all dfs into one
signest_all <- dplyr::bind_rows(signtest_mlit1000_all,
                              signtest_mlit250_all,
                              signtest_flit10_all,
                              signtest_flit1000_all,
                              signtest_flit250_all,
                              signtest_llit10_all,
                              signtest_llit250_all,
                              signtest_llit1000_all,
                              signtest_tat250_all,
                              signtest_tat1000_all,
                              signtest_is_all,
                              signtest_iv_all)

# Apply multiple corrections
signtest_final <- signest_all %>% 
  mutate(p.adj = stats::p.adjust(p,
                           "fdr", # we choose FDR (or BH - same thing) as method
                           n=length(p))) %>% # we want to correct for all comparisons, i.e. n=12
  rstatix::add_significance("p.adj") %>%
  dplyr::relocate(metric, .before= .y.) 
```

### Investigating the significant differences
In the t-tests above, we observe a significance difference in the metrics TAT 250 and TAT 1000 when calculated in the raw dataset, wear log dataset and clusters dataset. Next, we want to know: does this correlate with the compliance in using the black bag? We have this information from the bag_activity_prc script in the variable per_bag_use. Below is a repetition of how that was calculated
```{r}
 bag_use <- df.LL.nosleep %>%
  group_by(Id) %>%
   mutate(bag_use = case_when(
     State == "off" & bag == 0 ~ "notused", #when State is off and bag is 0, it was not used
     State == "off" & bag == 1 ~ "used", #when state is off and bag is 1, it was used
     .default = NA_character_)) %>%
  ungroup()

per_bag_use <- bag_use %>%
  group_by(Id, bag_use) %>% 
  summarise(count = n()) %>% #calculating how many used and notused per participant
  filter(!is.na(bag_use)) %>% #eliminate NAs which correspond to when State is on or sleep
  complete(bag_use = c("used", "notused"), fill = list(count = 0)) %>% #if participant does not have values for "used" or "notused" because they either never used the bag, or always used it, we replace that with 0
  mutate(total = sum(count), #counting total entries per participant
         compliance_per = if_else(bag_use == "used", (count*100)/total, NA), #calculating % of "used" over total entries
         compliance_per = round(compliance_per, 1)) %>% #rounding the percentage value to 1 decimal point
  filter(!is.na(compliance_per)) #eliminate the NA that comes from the ifelse

```

#### Combining per_bag_use with the TAT dfs
```{r}
# Turning deltas into long form to perform computations
  tat250_deltas_long <- tat250_all %>%
  pivot_longer(cols = c(delta_wrlg, delta_clusters),
               names_to = "metric",
               values_to = "delta")

# Merging the bag use info 
tat250_deltas_long <- tat250_deltas_long %>%
  left_join(per_bag_use, by = "Id")

# Plotting



ggplot(tat250_deltas_long, aes(x = as.numeric(delta), y = compliance_per, colour = metric)) +
    geom_jitter() +
    scale_x_continuous(breaks = c(0 , -250, -500, -750),
                       labels = function(x) sprintf("%.2f mins", x / 60)) + # Format with 2 decimal places 
    labs(x = "Delta TAT 250", y = "Percentage bag use (%)", title = "TAT 250 lx") +
    theme_bw() +
    theme(aspect.ratio = 1)
  
```
# Do the same for TAT 1000
```{r}
# Turning deltas into long form to perform computations
  tat1000_deltas_long <- tat1000_all %>%
  pivot_longer(cols = c(delta_wrlg, delta_clusters),
               names_to = "metric",
               values_to = "delta")

# Merging the bag use info 
tat1000_deltas_long <- tat1000_deltas_long %>%
  left_join(per_bag_use, by = "Id")

# Plotting

ggplot(tat1000_deltas_long, aes(x = as.numeric(delta), y = compliance_per, colour = metric)) +
    geom_jitter() +
    scale_x_continuous(breaks = c(0 , -250, -500, -750),
                       labels = function(x) sprintf("%.2f mins", x / 60)) + # Format with 2 decimal places 
    labs(x = "Delta TAT 1000", y = "Percentage bag use (%)", title = "TAT 1000 lx") +
    theme_bw() +
    theme(aspect.ratio = 1)
```
## Calculating mean and sd of TAT250 in order to report result of the t-test
```{r}
# dfs list
metrics_dfs <- list(mlit250_all = mlit250_all,
                    mlit1000_all = , llit10_all, llit250_all, llit1000_all, flit10_all, flit250_all, flit1000_all, tat1000_all, tat250_all)

metrics_means <- function(df) {
  df %>%
    summarise(
      mean_ids_raw = style_time(mean(as.numeric(mean_raw), na.rm = TRUE)),
      sd_ids_raw = style_time(sd(as.numeric(mean_raw), na.rm = TRUE)),
      mean_ids_wrlg = style_time(mean(as.numeric(mean_wrlg), na.rm = TRUE)),
      sd_ids_wrlg = style_time(sd(as.numeric(mean_wrlg), na.rm = TRUE)),
      mean_ids_clusters = style_time(mean(as.numeric(mean_clusters), na.rm = TRUE)),
      sd_ids_clusters = style_time(sd(as.numeric(mean_clusters), na.rm = TRUE))
    )
}

#Empty list to store results

metrics_list <- list()

#For loop to pass all dfs

for (i in seq_along(metrics_dfs)) {
  metrics_list[[i]] <- metrics_means(metrics_dfs[[i]])
}

# Convert the list of data frames to a single data frame
metrics_means_df <- bind_rows(metrics_list, .id = "dataset_id")
  

```

