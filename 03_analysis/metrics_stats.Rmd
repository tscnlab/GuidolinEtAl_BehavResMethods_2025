---
title: "metrics_stats"
author: "Carolina Guidolin"
date: "2024-12-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Aim
To calculate differences between metrics calculated in the script metrics_comparison.Rmd. Specifically, we will be using a t-test to do this.

## Let's first check the normality of our data
### Import the norm_check functions before running this. 
```{r}
# Function to check normality
base::source("D:/cyepi/code/03_analysis/functions/norm_check_funs.R")
```


```{r}
# Create a list of the dfs containing the metrics 
metrics_dfs <- list(mlit250_all, mlit1000_all, llit10_all, llit250_all, llit1000_all, flit10_all, flit250_all, flit1000_all, tat1000_all, tat250_all)

# Visualise normality of the means for each df

for (df in metrics_dfs) {

    print(norm_check_means(df))
  
}

## The distribution looks more or less normal, and we can proceed with a paired t-test on the means

# Checking the normality of the deltas
for (df in metrics_dfs) {

    print(norm_check_deltas(df))
  
}

## The deltas are not normally distributed

```
### Performing the paired sample Student t-test on the means 
#### First, we  create a function to perform the t-test for all metrics
```{r}
# T-test for the means
## First, we create a function for the metrics that have been calculated as average of 6 participation days
## These are: mlit250, mlit1000, llit10, llit250, llit1000, flit10, flit250, flit1000, tat1000, tat250

ttest_means <- function (df) {
  
  # Get the name of the input df as a string
  df_name <- deparse(substitute(df))
  
# Turning df into long form to perform computations
  df_long <- df %>%
  pivot_longer(cols = c(mean_raw, mean_wrlg, mean_clusters),
               names_to = "dataset",
               values_to = "mean")
  
  # Turn mean column to numeric (seconds)
    df_long <- df_long %>%
    mutate(mean = as.numeric(mean))
  
    # Performing t-test
  t_test <- df_long %>%
    rstatix::t_test(mean ~ dataset, paired = TRUE) %>%
    rstatix::add_significance("p") %>%
    select(-c(p.adj, p.adj.signif))
  
 # Computing Cohen's D
  cohens_d <- df_long %>%
    rstatix::cohens_d(mean ~ dataset, paired = TRUE)
  
  # Merging Cohen's D into t-test results
  t_test <- t_test %>%
    mutate(cohens_d = cohens_d$effsize)  # Add Cohen's D as a new column
  
  # Adding a column indicating which metric the t-test corresponds
  t_test$metric <- (df_name)
  
  return(t_test)
  
}    

## For the two remaining metrics (IS and IV), we are calculating t-test statistics separately


```

#### Applying the function to the metrics dfs
```{r}

#MLiT250
mlit250_ttest <- ttest_means(mlit250_all)

# MLiT1000
mlit1000_ttest <- ttest_means(mlit1000_all)

# FLitT 10
flit10_ttest <- ttest_means(flit10_all)

#FLitT250
flit250_ttest <- ttest_means(flit250_all)

#FLiT1000
flit1000_ttest <- ttest_means(flit1000_all)

# LLitT 10
llit10_ttest <- ttest_means(llit10_all)

# LLitT 250
llit250_ttest <- ttest_means(llit250_all)

# LLitT 1000
llit1000_ttest <- ttest_means(llit1000_all)

# TAT 250
tat250_ttest <- ttest_means(tat250_all)

# TAT 1000
tat1000_ttest <- ttest_means(tat1000_all)


```

### Peform t-test on remaining metrics (IV and IS)
```{r}
# Turning into long format
iv_means_long <- iv_all %>%
  pivot_longer(cols = c(IV_raw, IV_wrlg, IV_clusters),
               names_to = "dataset",
               values_to = "mean") 

is_means_long <- is_all %>%
  pivot_longer(cols = c(IS_raw, IS_wrlg, IS_clusters),
               names_to = "dataset",
               values_to = "mean")

# Performing the t-test
iv_ttest <- iv_means_long %>%
    rstatix::t_test(mean ~ dataset, paired = TRUE) %>%
    mutate(metric = "iv") %>%
    rstatix::add_significance("p") %>%
    select(-c(p.adj, p.adj.signif))

is_ttest <- is_means_long %>%
    rstatix::t_test(mean ~ dataset, paired = TRUE)  %>%
    mutate(metric = "is") %>%
    rstatix::add_significance("p") %>%
    select(-c(p.adj, p.adj.signif)) 
  

cohens_d_iv <- iv_means_long %>%
  rstatix::cohens_d(mean ~ dataset, paired = TRUE)

cohens_d_is <- is_means_long %>%
    rstatix::cohens_d(mean ~ dataset, paired = TRUE)

iv_ttest <- iv_ttest %>%
    mutate(cohens_d = cohens_d_iv$effsize)  # Add Cohen's D as a new column
 
is_ttest <- is_ttest %>%
    mutate(cohens_d = cohens_d_is$effsize)  # Add Cohen's D as a new column
 
  


#Combining all dfs into one
ttest_all <- dplyr::bind_rows(mlit250_ttest,
                              mlit1000_ttest,
                              flit10_ttest,
                              flit250_ttest,
                              flit1000_ttest,
                              llit10_ttest,
                              llit250_ttest,
                              llit1000_ttest,
                              tat250_ttest,
                              tat1000_ttest,
                              iv_ttest,
                              is_ttest)

# Apply multiple corrections

ttest_final <- ttest_all %>% 
  mutate(p.adj = stats::p.adjust(p,
                           "fdr", # we choose FDR (or BH - same thing) as method
                           n=length(p))) %>% # we want to correct for all comparisons, i.e. n=36
  rstatix::add_significance("p.adj") %>%
  dplyr::relocate(metric, .before= .y.) # re-order columns


# Rename some columns to eliminate the "_all" from the metric col
ttest_final <- ttest_final %>%
  mutate(metric = stringr::str_replace(metric, "_all$", ""))
```

## Turning this into a gt table
```{r}
ttest_table <- ttest_final %>%
  select(-c(.y., p.signif)) %>% #we do not need this col in the final summary
  gt::gt() %>%
  gt::tab_header(title = gt::md("**T-test results**")) %>% #Add title
  gt::cols_label(metric = "Metric",
             group1 = "Group 1",
             group2 = "Group 2",
             n1 = "N1",
             n2 = "N2",
             statistic = "Statistic",
             df = "Df",
             cohens_d = "Cohen's d",
             p.adj = "Adjusted p",
             p.adj.signif = "Significance") %>%
  gt::cols_align(align = "center",
                 columns = dplyr::everything()) %>%
  gt::tab_options(table.width=gt::pct(80)) #increasing table width so that it does not get cropped when saving
                
  
```
### Saving this gt object
```{r}
# Load chromote, needed to save using g
library(chromote)

# Make sure you set your path to Chrome using Sys.setenv(CHROMOTE_CHROME = "path/to/chrome.exe") and check this was correct by running chromote::find_chrome()

gt::gtsave(ttest_table,
           filename = "ttest_table.png",
           path = "Z:/nonwear_detection/preprint_figures/supplementary/",
           vwidth = 1450,
           vheight = 800)
```


### Investigating differences in the delta using a sign test
First, we need to write a function for this 
```{r}
# Sign-test for the deltas
signtest_deltas <- function (df) {
  
  # Get the name of the input df as a string
  df_name <- deparse(substitute(df))
  
# Turning df into long form to perform computations
  df_long <- df %>%
  pivot_longer(cols = c(delta_wrlg, delta_clusters),
               names_to = "metric",
               values_to = "delta")
  
  # Turn mean column to numeric (minutes)
    df_long <- df_long %>%
    mutate(delta = as.numeric(delta)/60) #turning the deltas into mins, this is optional (could keep them in secs)
  
    # Performing t-test
  signtest <- df_long %>%
    rstatix::sign_test(delta ~ metric) %>%
    rstatix::add_significance("p")
  
  # Adding a column indicating which metric the t-test corresponds
  signtest$metric <- (df_name)
  
   # Computing Cohen's D
  cohens_d <- df_long %>%
    rstatix::cohens_d(delta ~ metric)
  
  # Merging Cohen's D into t-test results
  signtest <- signtest %>%
    mutate(cohens_d = cohens_d$effsize)  # Add Cohen's D as a new column
  
 # Assigning dfs to dynamically named variables in the global environment
  assign(paste0(df_name, "_delta_long"), df_long, envir = .GlobalEnv)
  assign(paste0("signtest_", df_name), signtest, envir = .GlobalEnv)

}    

```

#### Run the sign test to all dfs (iv and is included, as the df structure enables this)
```{r}

#MLiT250
signtest_deltas(mlit250_all)

# MLiT1000
signtest_deltas(mlit1000_all)

# FLitT 10
signtest_deltas(flit10_all)

#FLitT250
signtest_deltas(flit250_all)

#FLiT1000
signtest_deltas(flit1000_all)

# LLitT 10
signtest_deltas(llit10_all)

# LLitT 250
signtest_deltas(llit250_all)

# LLitT 1000
signtest_deltas(llit1000_all)

# TAT 250
signtest_deltas(tat250_all)

# TAT 1000
signtest_deltas(tat1000_all)

# IV
signtest_deltas(iv_all)

# IS
signtest_deltas(is_all)

#Combining all dfs into one
signest_all <- dplyr::bind_rows(signtest_mlit1000_all,
                              signtest_mlit250_all,
                              signtest_flit10_all,
                              signtest_flit1000_all,
                              signtest_flit250_all,
                              signtest_llit10_all,
                              signtest_llit250_all,
                              signtest_llit1000_all,
                              signtest_tat250_all,
                              signtest_tat1000_all,
                              signtest_is_all,
                              signtest_iv_all)

# Apply multiple corrections
signtest_final <- signest_all %>% 
  mutate(p.adj = stats::p.adjust(p,
                           "fdr", # we choose FDR (or BH - same thing) as method
                           n=length(p))) %>% # we want to correct for all comparisons, i.e. n=12
  rstatix::add_significance("p.adj") %>%
  dplyr::relocate(metric, .before= .y.) 


```

### Investigating the significant differences
In the t-tests above, we observe a significance difference in the metrics TAT 250 and TAT 1000 when calculated in the raw dataset, wear log dataset and clusters dataset. Next, we want to know: does this correlate with the compliance in using the black bag? We have this information from the bag_activity_prc script in the variable per_bag_use. Below is a repetition of how that was calculated
```{r}
 bag_use <- df.LL.nosleep %>%
  group_by(Id) %>%
   mutate(bag_use = case_when(
     State == "off" & bag == 0 ~ "notused", #when State is off and bag is 0, it was not used
     State == "off" & bag == 1 ~ "used", #when state is off and bag is 1, it was used
     .default = NA_character_)) %>%
  ungroup()

per_bag_use <- bag_use %>%
  group_by(Id, bag_use) %>% 
  summarise(count = n()) %>% #calculating how many used and notused per participant
  filter(!is.na(bag_use)) %>% #eliminate NAs which correspond to when State is on or sleep
  complete(bag_use = c("used", "notused"), fill = list(count = 0)) %>% #if participant does not have values for "used" or "notused" because they either never used the bag, or always used it, we replace that with 0
  mutate(total = sum(count), #counting total entries per participant
         compliance_per = if_else(bag_use == "used", (count*100)/total, NA), #calculating % of "used" over total entries
         compliance_per = round(compliance_per, 1)) %>% #rounding the percentage value to 1 decimal point
  filter(!is.na(compliance_per)) #eliminate the NA that comes from the ifelse

```

#### Combining per_bag_use with the TAT dfs
```{r}
# Turning deltas into long form to perform computations
  tat250_deltas_long <- tat250_all %>%
  pivot_longer(cols = c(delta_wrlg, delta_clusters),
               names_to = "metric",
               values_to = "delta")

# Merging the bag use info 
tat250_deltas_long <- tat250_deltas_long %>%
  left_join(per_bag_use, by = "Id")

# Plotting



ggplot(tat250_deltas_long, aes(x = as.numeric(delta), y = compliance_per, colour = metric)) +
    geom_jitter() +
    scale_x_continuous(breaks = c(0 , -250, -500, -750),
                       labels = function(x) sprintf("%.2f mins", x / 60)) + # Format with 2 decimal places 
    labs(x = "Delta TAT 250", y = "Percentage bag use (%)", title = "TAT 250 lx") +
    theme_bw() +
    theme(aspect.ratio = 1)
  
```
# Do the same for TAT 1000
```{r}
# Turning deltas into long form to perform computations
  tat1000_deltas_long <- tat1000_all %>%
  pivot_longer(cols = c(delta_wrlg, delta_clusters),
               names_to = "metric",
               values_to = "delta")

# Merging the bag use info 
tat1000_deltas_long <- tat1000_deltas_long %>%
  left_join(per_bag_use, by = "Id")

# Plotting

ggplot(tat1000_deltas_long, aes(x = as.numeric(delta), y = compliance_per, colour = metric)) +
    geom_jitter() +
    scale_x_continuous(breaks = c(0 , -250, -500, -750),
                       labels = function(x) sprintf("%.2f mins", x / 60)) + # Format with 2 decimal places 
    labs(x = "Delta TAT 1000", y = "Percentage bag use (%)", title = "TAT 1000 lx") +
    theme_bw() +
    theme(aspect.ratio = 1)
```

## Calculating mean and sd of all timing functions in order to report result of the t-test
```{r}
# Define a function that calculates the mean of each id metric
## Note that this function uses the function style_time, which is already imported in metrics_comparison.Rmd from the file vis_metrics_funs.R

metrics_means <- function(df, df_name) {
  
  # Compute means and sds
  df <- df %>%
    summarise(
      mean_ids_raw = style_time(mean(as.numeric(mean_raw), na.rm = TRUE)),
      sd_ids_raw = style_time(sd(as.numeric(mean_raw), na.rm = TRUE)),
      mean_ids_wrlg = style_time(mean(as.numeric(mean_wrlg), na.rm = TRUE)),
      sd_ids_wrlg = style_time(sd(as.numeric(mean_wrlg), na.rm = TRUE)),
      mean_ids_clusters = style_time(mean(as.numeric(mean_clusters), na.rm = TRUE)),
      sd_ids_clusters = style_time(sd(as.numeric(mean_clusters), na.rm = TRUE))
    )
  
  #Adding col to specify which metric and rename the df
  df$metric <- df_name
  
  return(df)
}

# Now we run a for loop on different metric dfs to calculate the mean 

# Create a named list of data frames
metrics_dfs <- list(
  mlit250_all = mlit250_all,
  mlit1000_all = mlit1000_all,
  llit10_all = llit10_all,
  llit250_all = llit250_all,
  llit1000_all = llit1000_all,
  flit10_all = flit10_all,
  flit250_all = flit250_all,
  flit1000_all = flit1000_all,
  tat1000_all = tat1000_all,
  tat250_all = tat250_all
)

# Initiate empty list to store results
means_metric_list <- list()

# Create for loop 
for (df_name in names(metrics_dfs)) {
 
   df <- metrics_dfs[[df_name]]
  
  # Compute the means for the current data frame
  df_means <- metrics_means(df, df_name)
  
  # Store the resulting data frame in the list, using the index i
  means_metric_list[[df_name]] <- df_means
}

# Convert the list of data frames to a single data frame
means_metrics_df <- bind_rows(means_metric_list)
```

## Calculating mean and sd of is and iv
```{r}
is_means <- is_all %>%
    summarise(
      mean_ids_raw = mean(IS_raw, na.rm = TRUE),
      sd_ids_raw = sd(IS_raw, na.rm = TRUE),
      mean_ids_wrlg = mean(IS_wrlg, na.rm = TRUE),
      sd_ids_wrlg = sd(IS_wrlg, na.rm = TRUE),
      mean_ids_clusters = mean(IS_clusters, na.rm = TRUE),
      sd_ids_clusters = sd(IS_clusters, na.rm = TRUE),
    ) %>%
  mutate(metric = "is")

iv_means <- iv_all %>%
  summarise(
      mean_ids_raw = mean(IV_raw, na.rm = TRUE),
      sd_ids_raw = sd(IV_raw, na.rm = TRUE),
      mean_ids_wrlg = mean(IV_wrlg, na.rm = TRUE),
      sd_ids_wrlg = sd(IV_wrlg, na.rm = TRUE),
      mean_ids_clusters = mean(IV_clusters, na.rm = TRUE),
      sd_ids_clusters = sd(IV_clusters, na.rm = TRUE),
    ) %>%
  mutate(metric = "iv")

```

## Now we would like to have a single table for all metrics.
The issue with this is that bind_rows() will not merge cols that are of different data types (hms and numeric, in our case). Hence, we first convert everything to character, and then combine. We can do this since we are creating this table for display only, and not for any calculations.
```{r}
# Convert means_metrics_df cols to character
means_metrics_df <- means_metrics_df %>%
  mutate(dplyr::across(.fns = as.character))

# Convert numeric cols to character and round to 4 digits
iv_means <- iv_means %>%
  mutate(dplyr::across(where(is.numeric), ~ format(.x, digits = 4)))

# Convert numeric cols to character and round to 4 digits
is_means <- is_means %>%
  mutate(dplyr::across(where(is.numeric), ~ format(.x, digits = 4)))


# Combine the data using bind_rows
means_dfs <- dplyr::bind_rows(means_metrics_df, is_means, iv_means)

# Rename some columns to eliminate the "_all" from the metric col
means_dfs <- means_dfs %>%
  mutate(metric = stringr::str_replace(metric, "_all$", "")) %>%
  dplyr::relocate(metric, .before= mean_ids_raw) # re-order columns so that metric is first one
```

### Create gt table for this dataframe
```{r}
means_table <- means_dfs %>%
  gt::gt() %>%
  gt::tab_header(title = gt::md("**Means and SDs of light exposure metrics (n=12)**")) %>% #Add title
  gt::cols_label(metric = "Metric",
             mean_ids_raw = "Raw dataset (mean)",
             sd_ids_raw = "Raw dataset (SD)",
             mean_ids_wrlg = "Clean (Wear log) dataset (mean)",
             sd_ids_wrlg = "Clean (Wear log) dataset (SD)",
             mean_ids_clusters = "Clean (algorithm) dataset (mean)",
             sd_ids_clusters = "Clean (algorithm) dataset (SD)") %>%
  gt::cols_align(align = "center",
                 columns = dplyr::everything()) 

# Save the gt table
## Make sure you set your path to Chrome using Sys.setenv(CHROMOTE_CHROME = "path/to/chrome.exe") and check this was correct by running chromote::find_chrome()

gt::gtsave(means_table,
           filename = "means_table.png",
           path = "Z:/nonwear_detection/preprint_figures/supplementary/")


```
## Calculating the unstandardised effect size for the significant result, as we need to report this in the paper
```{r}
tat250_unst_effsize <- tat250_all %>%
  summarise(mean = mean(delta_clusters))
```

### Investigating correlation between off time based on ground truth and metrics
Note that you need wrlg_plots to be loaded and run.

```{r}
off_wrlg_duration <- int_duration %>%
  filter(State == "off") %>%
  select(Id, tot_intlength) 

off_wrlg_duration <-  off_wrlg_duration %>%
  mutate(tot_intlength = as.POSIXct(tot_intlength, format="%H:%M"))
```

## Start with IS
```{r}
is_off <- is_all %>%
  left_join(off_wlrg_duration, by = "Id")

p1 <- ggplot(is_off, aes(x=tot_intlength, y = delta_wrlg, color = Id)) +
  geom_jitter() +
  theme_bw() +
  scale_x_datetime() + 
  labs(x="Total non-wear timeduring the experiment (HH:MM)",
       y="Delta of X",
       title ="Difference in by amount of non-wear")

p2 <- ggplot(is_off, aes(x=tot_intlength, y = delta_clusters, color = Id)) +
  geom_jitter()
```

