---
title: "activity_transformations"
author: "Carolina Guidolin"
date: "2025-01-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Aim of this script
We want to undretand two things:
1) Should we use PIM, TAT or ZCM for operationalising activity levels?
2) Should we apply a pre-processing on the activity variable of choice (PIM/TAT/ZCM) prior to using our algorithm for detecting low activity clusters on the data?

## Let's start with the first point: PIM, TAT, or ZCM to quantify activity?
Citing Pilz et al. (2023): PIM is a measure of activity levels, ZCM is a measure of frequency of moevemnt, and TAT is a measure of time spent in motion in a given epoch. To get an idea of the difference in distributions between these three variables, we calculate descriptive statistics for each of them.

```{r}
pim_summary <- df.LL.nosleep %>%
  group_by(Id) %>%
  summarise(mean_pim = mean(PIM),
            sd_pim = sd(PIM),
            median_pim = median(PIM),
            min_pim = min(PIM),
            max_pim = max(PIM))

tat_summary <- df.LL.nosleep %>%
  group_by(Id) %>%
  summarise(mean_tat = mean(TAT),
            sd_tat = sd(TAT),
            median_tat = median(TAT),
            min_tat = min(TAT),
            max_tat = max(TAT))

zcm_summary <- df.LL.nosleep %>%
  group_by(Id) %>%
  summarise(mean_zcm = mean(ZCM),
            sd_zcm = sd(ZCM),
            median_zcm = median(ZCM),
            min_zcm = min(ZCM),
            max_zcm = max(ZCM))

```

### Next, we want to create PR curves for each of these variables

#### PIM
Since mean PIM values range from 50 (PID 206) to 234 (PID 204), we create a sequence of low values from 5 to 50, at 5 increment steps
```{r}
#Create a sequence of PIM thresholds at 5 unit steps
pimthresholds <- c(5,10, 15, 20, 25, 30, 35, 40, 45, 50)

#Empty list to store classification results
prc_list <- list()

#Running a for loop to generate a prc for all selected PIM thresholds 
for (threshold in pimthresholds) {
  
  prc_result <- generate_prc(
    dataset = df.LL.nosleep,
    low_var = "PIM",
    min_length = 54, #9 minutes (n of observations)
    max_interrupt = 0, #0 minute (n of observations)
    threshold = threshold
  )
  
  # Add the current threshold as a column in prc_result
  prc_result <- prc_result %>%
    mutate(threshold = threshold) # Add threshold column
  
  prc_list[[as.character(threshold)]] <- prc_result
  
}

#Turn into a df
prcurve_pim <- bind_rows(prc_list)

#Turn threshold to numeric for plotting
prcurve_pim$threshold <- as.numeric(prcurve_pim$threshold)

# Adding f1 value
prcurve_pim_f1 <- prcurve_pim %>%
  mutate(f1_score = (2 * PPV * TPR)/(PPV + TPR))

```

#### TAT
For TAT, the distribution is not as large and mean values range from 0.97 (PID 214) to 7.44 (PID 210). Thus, we choose smaller values ranging from 0.5 to 5.0 as thresholds
```{r}
#Create a sequence of TAT thresholds at 0.5 unit steps
tatthresholds <- c(0.5,1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5.0)

#Empty list to store classification results
prc_list <- list()

#Running a for loop to generate a prc for all selected TAT thresholds 
for (threshold in tatthresholds) {
  
  prc_result <- generate_prc(
    dataset = df.LL.nosleep,
    low_var = "TAT",
    min_length = 54, #9 minutes (n of observations)
    max_interrupt = 0, #0 minute (n of observations)
    threshold = threshold
  )
  
  # Add the current threshold as a column in prc_result
  prc_result <- prc_result %>%
    mutate(threshold = threshold) # Add threshold column
  
  prc_list[[as.character(threshold)]] <- prc_result
  
}

#Turn into a df
prcurve_tat <- bind_rows(prc_list)

#Turn threshold to numeric for plotting
prcurve_tat$threshold <- as.numeric(prcurve_tat$threshold)

# Adding f1 value

prcurve_tat_f1 <- prcurve_tat %>%
  mutate(f1_score = (2 * PPV * TPR)/(PPV + TPR))

```

#### ZCM
Similar to TAT, the values here range from 3.0 (PID 206) to 16.2 (PID 204). Hence, we will use the same threshold sequence. 
```{r}
#Create a sequence of ZCM thresholds at 5 unit steps
zcmthresholds <- c(0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5.0)

#Empty list to store classification results
prc_list <- list()

#Running a for loop to generate a prc for all selected PIM thresholds 
for (threshold in zcmthresholds) {
  
  prc_result <- generate_prc(
    dataset = df.LL.nosleep,
    low_var = "ZCM",
    min_length = 54, #9 minutes (n of observations)
    max_interrupt = 0, #0 minute (n of observations)
    threshold = threshold
  )
  
  # Add the current threshold as a column in prc_result
  prc_result <- prc_result %>%
    mutate(threshold = threshold) # Add threshold column
  
  prc_list[[as.character(threshold)]] <- prc_result
  
}

#Turn into a df
prcurve_zcm <- bind_rows(prc_list)

#Turn threshold to numeric for plotting
prcurve_zcm$threshold <- as.numeric(prcurve_zcm$threshold)

# Adding f1 value

prcurve_zcm_f1 <- prcurve_zcm %>%
  mutate(f1_score = (2 * PPV * TPR)/(PPV + TPR))
```

### Let's plot the three curves together to visualise them 
```{r}
# PIM
prc_pim_thresholds <- ggplot() +
   xlim(0,1) + 
   ylim(0,1) +
  geom_abline(slope = 0, intercept = 0.5, linetype = "dashed", color = "darkgrey") + #add a flat line which represents a baseline classifier
  geom_point(data = prcurve_pim, aes(x = TPR, y = PPV, colour = threshold)) +
  scale_colour_gradient(
     name = "PIM threshold",
     low = "blue", high = "lightblue",
     limits= c(5,50),
     guide = guide_colourbar(title.position = "top", title.hjust = 0.5)) +
  labs(x="True positive rate (recall)",
       y = "Positive predictive value \n(precision)",
       title = "Raw PIM threshold \nbased detection") +
   theme_bw() +
 theme(plot.title = element_text(hjust = 0.5, size = 20),
        axis.text = element_text(size = 16),
        axis.title = element_text(size = 16),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key.size = unit(8, "mm"),
        legend.position = "bottom",
        legend.box = "horizontal",
        plot.margin = unit(c(0,0.5,0,0), unit ="cm")) +
   coord_fixed(ratio = 1)

# TAT
prc_tat_thresholds <- ggplot() +
   xlim(0,1) + 
   ylim(0,1) +
  geom_abline(slope = 0, intercept = 0.5, linetype = "dashed", color = "darkgrey") + #add a flat line which represents a baseline classifier
  geom_point(data = prcurve_tat, aes(x = TPR, y = PPV, colour = threshold)) +
  scale_colour_gradient(
     name = "TAT threshold",
     low = "blue", high = "lightblue",
     limits= c(0.5,5),
     guide = guide_colourbar(title.position = "top", title.hjust = 0.5)) +
  labs(x="True positive rate (recall)",
       y = "Positive predictive value \n(precision)",
       title = "TAT threshold \nbased detection") +
   theme_bw() +
 theme(plot.title = element_text(hjust = 0.5, size = 20),
        axis.text = element_text(size = 16),
        axis.title = element_text(size = 16),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key.size = unit(8, "mm"),
        legend.position = "bottom",
        legend.box = "horizontal",
        plot.margin = unit(c(0,0.5,0,0), unit ="cm")) +
   coord_fixed(ratio = 1)

# ZCM
prc_zcm_thresholds <- ggplot() +
   xlim(0,1) + 
   ylim(0,1) +
  geom_abline(slope = 0, intercept = 0.5, linetype = "dashed", color = "darkgrey") + #add a flat line which represents a baseline classifier
  geom_point(data = prcurve_zcm, aes(x = TPR, y = PPV, colour = threshold)) +
  scale_colour_gradient(
     name = "ZCM threshold",
     low = "blue", high = "lightblue",
     limits= c(0.5,5),
     guide = guide_colourbar(title.position = "top", title.hjust = 0.5)) +
  labs(x="True positive rate (recall)",
       y = "Positive predictive value \n(precision)",
       title = "ZCM threshold \nbased detection") +
   theme_bw() +
 theme(plot.title = element_text(hjust = 0.5, size = 20),
        axis.text = element_text(size = 16),
        axis.title = element_text(size = 16),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key.size = unit(8, "mm"),
        legend.position = "bottom",
        legend.box = "horizontal",
        plot.margin = unit(c(0,0.5,0,0), unit ="cm")) +
   coord_fixed(ratio = 1)

# Combining in one single plot
multiplot <- cowplot::plot_grid(prc_pim_thresholds, prc_tat_thresholds, prc_zcm_thresholds,
                                labels = c("A", "B", "C"),
                                ncol = 3,
                                nrow = 1,
                                align = "hv")

# Saving the comined plot
ggsave(filename = "pim_tat_zcm_comparison.png",
       plot = multiplot,
       width = 14, 
       height = 6,
       dpi = 600, 
       bg = "white",
       path = "H:/nonwear_detection/preprint_figures/supplementary")

```

### What does this tell us?
Using PIM, TAT, or ZCM does not lead to huge differences in the output of out algorithm.

## Now let's move to the second point: should we pre-process PIM data prior to applying our cluster-detecting algorithm?
Since PIM data contains many small values (including 0) and large values, it would be a good idea to:
1) Transform it into log scale;
2) Normalise each value to the maximum value for each participant

```{r}
# Step 1: Transforming PIM to logarithmic scale

log.df.LL.nosleep <- df.LL.nosleep %>%
  mutate(PIM = PIM+0.1, #first, add a small value of 0.1 to enable log transformation
         log.PIM = log10(PIM)) # apply transformation 

# Before proceeding to step 2: what would happen if we apply our algorithm here?

## Create a sequence of PIM thresholds in log scale, at 5 unit steps
log_pimthresholds <- log10(c(5,10, 15, 20, 25, 30, 35, 40, 45, 50))

## Empty list to store classification results
prc_list <- list()

## Running a for loop to generate a prc for all selected PIM thresholds (log scale)
for (threshold in log_pimthresholds) {
  
  prc_result <- generate_prc(
    dataset = log.df.LL.nosleep,
    low_var = "log.PIM",
    min_length = 54, #9 minutes (n of observations)
    max_interrupt = 0, #0 minute (n of observations)
    threshold = threshold
  )
  
  # Add the current threshold as a column in prc_result
  prc_result <- prc_result %>%
    mutate(threshold = threshold) # Add threshold column
  
  prc_list[[as.character(threshold)]] <- prc_result
  
}

## Turn into a df
log_prcurve_pim <- bind_rows(prc_list)

## Adding f1 value
log_prcurve_pim_f1 <- log_prcurve_pim %>%
  mutate(f1_score = (2 * PPV * TPR)/(PPV + TPR))

# Plotting this pr curve
prc_pim_log <- ggplot() +
   xlim(0,1) + 
   ylim(0,1) +
  geom_abline(slope = 0, intercept = 0.5, linetype = "dashed", color = "darkgrey") + #add a flat line which represents a baseline classifier
  geom_point(data = log_prcurve_pim, aes(x = TPR, y = PPV, colour = threshold)) +
  scale_colour_gradient(
     name = "Log PIM threshold",
     low = "blue", high = "lightblue",
     limits= c(log10(5),log10(50)),
     guide = guide_colourbar(title.position = "top", title.hjust = 0.5)) +
  labs(x="True positive rate (recall)",
       y = "Positive predictive value \n(precision)",
       title = "Log PIM threshold \nbased detection") +
   theme_bw() +
 theme(plot.title = element_text(hjust = 0.5, size = 20),
        axis.text = element_text(size = 16),
        axis.title = element_text(size = 16),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key.size = unit(8, "mm"),
        legend.position = "bottom",
        legend.box = "horizontal",
        plot.margin = unit(c(0,0.5,0,0), unit ="cm")) +
   coord_fixed(ratio = 1)


```

### What does this tell us? 
The f1 scores for the log transformed PIM, using the same thresholds of the raw PIM (but taking the log10 of them, i.e. log10(5) instead of 5, and so on), is equivalent to the f1 score for the raw data. This can be seen if you compare the data frames prcurve_pim_f1 and log_prcurve_pim_f1: the f1 scores are the same for the corresponding PIM thresholds. This result is to be expected, and can be used as a sanity check. 

## We can proceed to step 2: the normalisation
There are several ways of applying a normalisation to the data. To understand which one we want to apply, let's first take a look at the data by plotting a simple histogram of the log.PIM to understand its distribution.
```{r}
ggplot(log.df.LL.nosleep) +
  geom_histogram(aes(x=log.PIM))
```

We see that because a lot of the raw values correspond to zero values, there is a high frequency of log.PIM = -1. The distribution is definitely non-normal. For this reason, we choose to normalise our data using a min-max normalisation.

```{r}
# Step 2: Apply min-max transformation to the log data

## Function that will normalise
min_max_normalisation <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

## Normalise activity within each Id
normalised_log_pim_df <- log.df.LL.nosleep %>% 
  group_by(Id) %>% # we want to normalise within each Id 
  mutate(norm_log.pim = min_max_normalisation(log.PIM)) %>%
  ungroup()

## Let's visualise th distribution of the normalised log.PIM
ggplot(normalised_log_pim_df) +
  geom_histogram(aes(x=norm_log.pim))
```
As expected, the dirtibution of the data per se has not changed, but the values on the x axis have been transformed so that they fall between 0 and 1. 

## Apply cluster algorithm to normalised log PIM
```{r}
#Create a sequence of PIM thresholds at 0.01 unit steps (because PIM values only range from 0 to 1)
norm_pimthresholds <- c(0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1)

#Empty list to store classification results
prc_list <- list()

#Running a for loop to generate a prc for all selected PIM thresholds 
for (threshold in norm_pimthresholds) {
  
  prc_result <- generate_prc(
    dataset = normalised_log_pim_df,
    low_var = "norm_log.pim",
    min_length = 54, #9 minutes (n of observations)
    max_interrupt = 0, #0 minute (n of observations)
    threshold = threshold
  )
  
  # Add the current threshold as a column in prc_result
  prc_result <- prc_result %>%
    mutate(threshold = threshold) # Add threshold column
  
  prc_list[[as.character(threshold)]] <- prc_result
  
}

#Turn into a df
norm_log_prcurve_pim <- bind_rows(prc_list)

#Turn threshold to numeric for plotting
norm_log_prcurve_pim$threshold <- as.numeric(norm_log_prcurve_pim$threshold)

# Adding f1 value
norm_log_prcurve_pim_f1 <- norm_log_prcurve_pim %>%
  mutate(f1_score = (2 * PPV * TPR)/(PPV + TPR))

# Plot this PR curve
prc_pim_log_norm <- ggplot() +
   xlim(0,1) + 
   ylim(0,1) +
  geom_abline(slope = 0, intercept = 0.5, linetype = "dashed", color = "darkgrey") + #add a flat line which represents a baseline classifier
  geom_point(data = norm_log_prcurve_pim, aes(x = TPR, y = PPV, colour = threshold)) +
  scale_colour_gradient(
     name = "Normalised PIM threshold",
     low = "blue", high = "lightblue",
     limits= c(0.01, 0.1),
     breaks = c(0.01, 0.05, 0.1),
     labels = c(0.01, 0.05, 0.1),
     guide = guide_colourbar(title.position = "top", title.hjust = 0.5)) +
  labs(x="True positive rate (recall)",
       y = "Positive predictive value \n(precision)",
       title = "Log-transformed and normalised \nPIM threshold based detection") +
   theme_bw() +
 theme(plot.title = element_text(hjust = 0.5, size = 20),
        axis.text = element_text(size = 16),
        axis.title = element_text(size = 16),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key.size = unit(8, "mm"),
        legend.position = "bottom",
        legend.box = "horizontal",
        plot.margin = unit(c(0,0.5,0,0), unit ="cm")) +
   coord_fixed(ratio = 1)
```

### What does this tell us? 
The f1 score of the cluster algorithm applied to the normalised log data is similar to that of the a) raw data and b) log data, with values all close to 0.52, regardless of the chosen threshold. 

### What if we normalised the data without any log transformation?
```{r}
# Apply min max normalisation to the raw data

## Function that will normalise - (same as above!)
min_max_normalisation <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

## Normalise activity within each Id
normalised_raw_pim_df <- df.LL.nosleep %>% 
  group_by(Id) %>% # we want to normalise within each Id 
  mutate(norm_pim = min_max_normalisation(PIM)) %>%
  ungroup()

## Let's visualise the distribution of the normalised raw PIM
ggplot(normalised_raw_pim_df) +
  geom_histogram(aes(x=norm_pim))
```
Now we apply our cluster algorithm to the normalised raw PIM data
```{r}
#Create a sequence of PIM thresholds at 0.001 unit steps (because PIM values only range from 0 to 1, and they are heavily skewed towards 0)
norm_pimthresholds <- c(0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01)

#Empty list to store classification results
prc_list <- list()

#Running a for loop to generate a prc for all selected PIM thresholds 
for (threshold in norm_pimthresholds) {
  
  prc_result <- generate_prc(
    dataset = normalised_raw_pim_df,
    low_var = "norm_pim",
    min_length = 54, #9 minutes (n of observations)
    max_interrupt = 0, #0 minute (n of observations)
    threshold = threshold
  )
  
  # Add the current threshold as a column in prc_result
  prc_result <- prc_result %>%
    mutate(threshold = threshold) # Add threshold column
  
  prc_list[[as.character(threshold)]] <- prc_result
  
}

#Turn into a df
norm_raw_prcurve_pim <- bind_rows(prc_list)

#Turn threshold to numeric for plotting
norm_raw_prcurve_pim$threshold <- as.numeric(norm_raw_prcurve_pim$threshold)

# Adding f1 value
norm_raw_prcurve_pim_f1 <- norm_raw_prcurve_pim %>%
  mutate(f1_score = (2 * PPV * TPR)/(PPV + TPR))

# Plot this PR curve
prc_pim_raw_norm <- ggplot() +
   xlim(0,1) + 
   ylim(0,1) +
  geom_abline(slope = 0, intercept = 0.5, linetype = "dashed", color = "darkgrey") + #add a flat line which represents a baseline classifier
  geom_point(data = norm_raw_prcurve_pim, aes(x = TPR, y = PPV, colour = threshold)) +
  scale_colour_gradient(
     name = "Normalised PIM threshold",
     low = "blue", high = "lightblue",
     limits= c(0.001, 0.01),
     breaks = c(0.001, 0.005, 0.01),
     labels = c(0.001, 0.005, 0.01),
     guide = guide_colourbar(title.position = "top", title.hjust = 0.5)) +
  labs(x="True positive rate (recall)",
       y = "Positive predictive value \n(precision)",
       title = "Raw and normalised \nPIM threshold based detection") +
   theme_bw() +
 theme(plot.title = element_text(hjust = 0.5, size = 20),
        axis.text = element_text(size = 16),
        axis.title = element_text(size = 16),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key.size = unit(8, "mm"),
        legend.position = "bottom",
        legend.box = "horizontal",
        plot.margin = unit(c(0,0.5,0,0), unit ="cm")) +
   coord_fixed(ratio = 1)
```

### What does this tell us?
Again, we get a best f1 score of arrpoximately 0.51, which is very similar to the f1 score obtained on A) the raw data, B) the log transformed data, and C) the log transformed and normalised data.

## Smoothing the data
Since none of the transformation applied actually improved the algorithm's performance, it would be interesting to see if smoothing the data actually improves the algorithm's performance. We do this using a sliding median with window of 10 minutes. We apply the smoothing directly to the raw data, i.e. without log transformation or normalisation first.

```{r}
rolled.pim <- df.LL.nosleep %>%
  group_by(Id) %>%
  mutate(rolled_median_PIM = zoo::rollapplyr(PIM, width = 60, FUN = median, fill = NA, align = "center")) %>%
  ungroup()

# To get an idea of the distribution of the data, let's calculate some descriptive stats
rolled_pim_summary <- rolled.pim %>%
  group_by(Id) %>%
  summarise(mean_pim = mean(rolled_median_PIM, na.rm = TRUE),
            sd_pim = sd(rolled_median_PIM, na.rm = TRUE),
            median_pim = median(rolled_median_PIM, na.rm = TRUE),
            min_pim = min(rolled_median_PIM, na.rm = TRUE),
            max_pim = max(rolled_median_PIM, na.rm = TRUE)) %>%
  ungroup()

# Visualise distribution 
ggplot(rolled.pim) +
  geom_histogram(aes(x=rolled_median_PIM)) ##very similar to the original distribution of PIM
```
### Applying the cluster algorithm to the rolled df
```{r}
#Create a sequence of PIM thresholds at 5 unit steps
pimthresholds <- c(5,10, 15, 20, 25, 30, 35, 40, 45, 50)

#Empty list to store classification results
prc_list <- list()

#Running a for loop to generate a prc for all selected PIM thresholds 
for (threshold in pimthresholds) {
  
  prc_result <- generate_prc(
    dataset = rolled.pim,
    low_var = "rolled_median_PIM",
    min_length = 54, #9 minutes (n of observations)
    max_interrupt = 0, #0 minute (n of observations)
    threshold = threshold
  )
  
  # Add the current threshold as a column in prc_result
  prc_result <- prc_result %>%
    mutate(threshold = threshold) # Add threshold column
  
  prc_list[[as.character(threshold)]] <- prc_result
  
}

#Turn into a df
rolled_raw_prcurve_pim <- bind_rows(prc_list)

#Turn threshold to numeric for plotting
rolled_raw_prcurve_pim$threshold <- as.numeric(rolled_raw_prcurve_pim$threshold)

# Adding f1 value
rolled_raw_prcurve_pim_f1 <- rolled_raw_prcurve_pim %>%
  mutate(f1_score = (2 * PPV * TPR)/(PPV + TPR))

# Plot this PR curve
prc_pim_rolled_raw <- ggplot() +
   xlim(0,1) + 
   ylim(0,1) +
  geom_abline(slope = 0, intercept = 0.5, linetype = "dashed", color = "darkgrey") + #add a flat line which represents a baseline classifier
  geom_point(data = rolled_raw_prcurve_pim, aes(x = TPR, y = PPV, colour = threshold)) +
  scale_colour_gradient(
     name = "PIM threshold",
     low = "blue", high = "lightblue",
     limits= c(5, 50),
     guide = guide_colourbar(title.position = "top", title.hjust = 0.5)) +
  labs(x="True positive rate (recall)",
       y = "Positive predictive value \n(precision)",
       title = "Smoothed PIM threshold \nbased detection") +
   theme_bw() +
 theme(plot.title = element_text(hjust = 0.5, size = 20),
        axis.text = element_text(size = 16),
        axis.title = element_text(size = 16),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key.size = unit(8, "mm"),
        legend.position = "bottom",
        legend.box = "horizontal",
        plot.margin = unit(c(0,0.5,0,0), unit ="cm")) +
   coord_fixed(ratio = 1)

```

### What does this tell us?
Smoothing on raw data is actually not benefiting the performance of the algorithm.

## What if we smooth the log data and apply the algorithm after the log transformation? 
```{r}
# First, we have to apply a rolling median to the log transformed data
rolled.log.pim <- log.df.LL.nosleep %>%
  group_by(Id) %>%
  mutate(rolled_median_PIM = zoo::rollapplyr(log.PIM, width = 60, FUN = median, fill = NA, align = "center")) %>%
  ungroup()

#Create a sequence of PIM thresholds at 5 unit steps
log_pimthresholds <- log10(c(5,10, 15, 20, 25, 30, 35, 40, 45, 50))

#Empty list to store classification results
prc_list <- list()

#Running a for loop to generate a prc for all selected PIM thresholds 
for (threshold in log_pimthresholds) {
  
  prc_result <- generate_prc(
    dataset = rolled.log.pim,
    low_var = "rolled_median_PIM",
    min_length = 54, #9 minutes (n of observations)
    max_interrupt = 0, #0 minute (n of observations)
    threshold = threshold
  )
  
  # Add the current threshold as a column in prc_result
  prc_result <- prc_result %>%
    mutate(threshold = threshold) # Add threshold column
  
  prc_list[[as.character(threshold)]] <- prc_result
  
}

#Turn into a df
rolled_log_prcurve_pim <- bind_rows(prc_list)

#Turn threshold to numeric for plotting
rolled_log_prcurve_pim$threshold <- as.numeric(rolled_log_prcurve_pim$threshold)

# Adding f1 value
rolled_log_prcurve_pim_f1 <- rolled_log_prcurve_pim %>%
  mutate(f1_score = (2 * PPV * TPR)/(PPV + TPR))

# Plot this PR curve
prc_pim_rolled_log <- ggplot() +
   xlim(0,1) + 
   ylim(0,1) +
  geom_abline(slope = 0, intercept = 0.5, linetype = "dashed", color = "darkgrey") + #add a flat line which represents a baseline classifier
  geom_point(data = rolled_log_prcurve_pim, aes(x = TPR, y = PPV, colour = threshold)) +
  scale_colour_gradient(
     name = "Log PIM threshold",
     low = "blue", high = "lightblue",
     limits= c(log10(5), log10(50)),
     guide = guide_colourbar(title.position = "top", title.hjust = 0.5)) +
  labs(x="True positive rate (recall)",
       y = "Positive predictive value \n(precision)",
       title = "Log-transformed and smoothed \nPIM threshold based detection") +
   theme_bw() +
 theme(plot.title = element_text(hjust = 0.5, size = 20),
        axis.text = element_text(size = 16),
        axis.title = element_text(size = 16),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key.size = unit(8, "mm"),
        legend.position = "bottom",
        legend.box = "horizontal",
        plot.margin = unit(c(0,0.5,0,0), unit ="cm")) +
   coord_fixed(ratio = 1)
```

We get the same f1 values as the rolled_raw df, which we would expect!

## Trying one final thing 
First, we apply all three transformations to the data
1) Log transformation
2) Smoothing 
3) Normalising 

Then, we apply the algorithm 
```{r}
# We already have a log transformed and smoothed dataset from the code chunk above, i.e. rolled.log.pim
# This means that we jump to step 3 and apply a normalisation to the rolled.log.pim df 

## We need to change the normalisation function so that it handles NA values resulting from the smoothing

na_min_max_normalisation <- function(x) {
  # Apply the normalisation only if the value is not NA
  if (all(is.na(x))) {
    return(rep(NA_real_, length(x)))  # If values are NA, return a vector of NAs
  } else {
    # Normalise only the non-NA values and handle each element
    min_val <- min(x, na.rm = TRUE)
    max_val <- max(x, na.rm = TRUE)
    return((x - min_val) / (max_val - min_val))
    }
  }

# Apply the normalisation
norm_rolled_log_pim <- rolled.log.pim %>%
  group_by(Id) %>% # we want to normalise within each Id 
  mutate(n_r_l_pim = na_min_max_normalisation(rolled_median_PIM)) %>%
  ungroup()

# Apply the algorithm
#Create a sequence of PIM thresholds at 0.001 unit steps (because PIM values only range from 0 to 1, and thy are heavily skewed towards 0)
norm_pimthresholds <- c(0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01)

#Empty list to store classification results
prc_list <- list()

#Running a for loop to generate a prc for all selected PIM thresholds 
for (threshold in norm_pimthresholds) {
  
  prc_result <- generate_prc(
    dataset = norm_rolled_log_pim,
    low_var = "n_r_l_pim",
    min_length = 54, #9 minutes (n of observations)
    max_interrupt = 0, #0 minute (n of observations)
    threshold = threshold
  )
  
  # Add the current threshold as a column in prc_result
  prc_result <- prc_result %>%
    mutate(threshold = threshold) # Add threshold column
  
  prc_list[[as.character(threshold)]] <- prc_result
  
}

#Turn into a df
norm_rolled_log_prcurve_pim <- bind_rows(prc_list)

#Turn threshold to numeric for plotting
norm_rolled_log_prcurve_pim$threshold <- as.numeric(norm_rolled_log_prcurve_pim$threshold)

# Adding f1 value
norm_rolled_log_prcurve_pim_f1 <- norm_rolled_log_prcurve_pim %>%
  mutate(f1_score = (2 * PPV * TPR)/(PPV + TPR))

# Plotting this final PR curve
prc_pim_norm_rolled_log <- ggplot() +
   xlim(0,1) + 
   ylim(0,1) +
  geom_abline(slope = 0, intercept = 0.5, linetype = "dashed", color = "darkgrey") + #add a flat line which represents a baseline classifier
  geom_point(data = norm_rolled_log_prcurve_pim, aes(x = TPR, y = PPV, colour = threshold)) +
  scale_colour_gradient(
     name = "Normalised PIM threshold",
     low = "blue", high = "lightblue",
     limits= c(0.001, 0.01),
     breaks = c(0.001, 0.005, 0.01),
     labels = c(0.001, 0.005, 0.01),
     guide = guide_colourbar(title.position = "top", title.hjust = 0.5)) +
  labs(x="True positive rate (recall)",
       y = "Positive predictive value \n(precision)",
       title = "Log-transformed, smoothed and \nnormalised PIM threshold based detection") +
   theme_bw() +
 theme(plot.title = element_text(hjust = 0.5, size = 20),
        axis.text = element_text(size = 16),
        axis.title = element_text(size = 16),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key.size = unit(8, "mm"),
        legend.position = "bottom",
        legend.box = "horizontal",
        plot.margin = unit(c(0,0.5,0,0), unit ="cm")) +
   coord_fixed(ratio = 1)
```

# Putting all of these plots into a single multiplot
```{r}
# Combining in one single plot
preprocess_multiplot <- cowplot::plot_grid(prc_pim_thresholds, 
                                           prc_pim_raw_norm,
                                           prc_pim_rolled_raw,
                                           prc_pim_log,
                                           prc_pim_log_norm,
                                           prc_pim_rolled_log,
                                           prc_pim_norm_rolled_log,
                                labels = c("A", "B", "C", "D", "E", "F", "G"),
                                ncol = 3,
                                align = "hv")

# Saving the plot
ggsave(filename = "pim_pre-process.png",
       plot = preprocess_multiplot,
       width = 14, 
       height = 14,
       dpi = 600, 
       bg = "white",
       path = "Z:/nonwear_detection/preprint_figures/supplementary")
```

