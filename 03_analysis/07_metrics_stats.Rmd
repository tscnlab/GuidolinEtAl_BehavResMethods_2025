---
title: "metrics_stats"
author: "Carolina Guidolin"
date: "2024-12-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Aim
To calculate differences between metrics calculated in the script 06_metrics_comparison.Rmd. Specifically, we will be using a t-test to do this.

## Let's first check the normality of our data
### Import the norm_check functions before running this as well as necessary packages
```{r}
# Function to check normality
base::source(here::here("03_analysis", "functions", "norm_check_funs.R"))

library(ggpubr)
library(rstatix)
```

### Testing for normality of residuals 
```{r}
options(scipen = 999) # avoid scientific notation 

# Create list of data frames containing metric values
metrics_dfs <- list(
  mlit250_all,
  mlit1000_all,
  llit10_all,
  llit250_all,
  llit1000_all,
  flit10_all,
  flit250_all,
  flit1000_all,
  tat1000_all,
  tat250_all,
  mean_all,
  m10_all
)

# Visualise normality of the means for each df

for (df in metrics_dfs) {

    print(norm_check_means(df))
  
}

## The distribution does not look normal, and for several metrics the Shapiro Wilk test also returns significant results
## Hence, non-parametric alternative is needed

```

### Performing the non-parametric Friedman test for the metrics, and calculate pairwise comparisons (post-hoc tests) using Wilcoxon test 

#### First, we  create a function to perform the two test for all metrics
```{r}
# Friedman test
## First, we create a function for the metrics that have been calculated as average of 6 participation days
## These are: mlit250, mlit1000, llit10, llit250, llit1000, flit10, flit250, flit1000, tat1000, tat250, mean (daytime, M10m)

friedman_and_posthoc <- function(df, pval_threshold = 0.05, metric_name = NULL) {
  
  # Get the name of the input df as a string
    if (is.null(metric_name)) {
    metric_name <- deparse(substitute(df))  
  }
  
  # Turn into long format
  df_long <- df %>%
 # Drop any delta cols and sd cols if they exist
    select(-any_of(c("delta_wrlg", "delta_clusters", "sd_raw", "sd_wrlg", "sd_clusters"))) %>%
    # Automatically select *_raw, *_wrlg, *_clusters
    pivot_longer(
      cols = matches("(_raw|_wrlg|_clusters)$"),
      names_to = "dataset",
      values_to = "value"
    ) %>%
    mutate(value = as.numeric(value),
           Id = as.factor(Id)) %>%
    ungroup()
  
  summary(df_long$value)
  
  # Friedman test and effect size (Kendall's W)
  friedman <- df_long %>%
    rstatix::friedman_test(value ~ dataset | Id) %>%
    mutate(
      kendallsw = rstatix::friedman_effsize(df_long, value ~ dataset | Id)$effsize,
      metric = metric_name
    )
  
  # Post-hoc only if friedman test is significant
  if (friedman$p < pval_threshold) {
    # Perform Wilcoxon pairwise comparisons
    posthoc <- df_long %>%
      rstatix::pairwise_wilcox_test(
        value ~ dataset,
        paired = TRUE,
        p.adjust.method = "fdr"
      ) %>%
      # Add metric name
      mutate(
        metric = metric_name # add metric name
    )
  } 
  else {
  posthoc <- NULL
  }
  
return(list(
    friedman = friedman,
    posthoc = posthoc
  ))
  
}

```

### Function to perform equivalence testing
```{r}
perform_equivalence_tests <- function(df, metric_name = NULL, pval_threshold = 0.05, equiv_bound = 0.5) {
  
  if (is.null(metric_name)) {
    metric_name <- deparse(substitute(df))
  }
  
  df_long <- df %>%
    # Drop any delta cols and sd cols if they exist
    select(-any_of(c("delta_wrlg", "delta_clusters", "sd_raw", "sd_wrlg", "sd_clusters"))) %>%
    pivot_longer(
      cols = matches("(_raw|_wrlg|_clusters)$"),
      names_to = "dataset",
      values_to = "value"
    ) %>%
    mutate(value = as.numeric(value),
           Id = as.factor(Id)) %>%
    ungroup()
  
  datasets <- unique(df_long$dataset)
  ids <- unique(df_long$Id)
  
  equivalence_results <- list()
  
  combs <- combn(datasets, 2)
  
  for (i in seq_len(ncol(combs))) {
    d1 <- combs[1, i]
    d2 <- combs[2, i]
    
    vals1 <- df_long %>% filter(dataset == d1) %>% arrange(Id) %>% pull(value)
    vals2 <- df_long %>% filter(dataset == d2) %>% arrange(Id) %>% pull(value)
    
    tost_res <- TOSTER::tsum_TOST(
      n = n,
      mean = mean_diff,
      sd = sd_diff,
      low_eqbound = low_eqbound,
      high_eqbound = high_eqbound,
      alpha = pval_threshold,
      var.equal = TRUE,
      verbose = FALSE
    )
    
    equivalence_results[[paste0(d1, "_vs_", d2)]] <- data.frame(
      comparison = paste(d1, "vs", d2),
      TOST_p_lower = tost_res$TOST$p.value[1],
      TOST_p_upper = tost_res$TOST$p.value[2],
      TOST_significant = all(tost_res$TOST$p.value < pval_threshold),
      metric = metric_name
    )
  }
  
  do.call(rbind, equivalence_results)
}
```


### Apply Friedman testing function to all metrics dfs
```{r}
library(purrr)

metrics_list <- list(
  mlit250_all = mlit250_all,
  mlit1000_all = mlit1000_all,
  llit10_all = llit10_all,
  llit250_all = llit250_all,
  llit1000_all = llit1000_all,
  flit10_all = flit10_all,
  flit250_all = flit250_all,
  flit1000_all = flit1000_all,
  tat1000_all = tat1000_all,
  tat250_all = tat250_all,
  mean_all = mean_all,
  m10_all = m10_all,
  iv_all = iv_all,
  is_all = is_all
)

results <- lapply(names(metrics_list), function(nm) {
  fried_res <- friedman_and_posthoc(metrics_list[[nm]], 0.05, nm)
  return(fried_res)
})

# Save results in dfs
friedman_all <- purrr::map_dfr(results, "friedman")
posthoc_all  <- purrr::map_dfr(results, "posthoc") 
```

### Should we adjust also across metrics (the p value)?
```{r}

```




```{r}
# Apply multiple corrections
ttest_final <- ttest_all %>% 
  mutate(p.adj = stats::p.adjust(p,
                           "fdr", # we choose FDR (or BH - same thing) as method
                           n=length(p))) %>% # we want to correct for all comparisons, i.e. n=36
  rstatix::add_significance("p.adj") %>%
  dplyr::relocate(metric, .before= .y.) # re-order columns

# Rename some columns to eliminate the "_all" from the metric col
ttest_final <- ttest_final %>%
  mutate(metric = stringr::str_replace(metric, "_all$", ""))
```

## Turning this into a gt table
```{r}
ttest_table <- ttest_final %>%
  select(-c(.y., p.signif)) %>% #we do not need this col in the final summary
  gt::gt() %>%
  gt::tab_header(title = gt::md("**T-test results**")) %>% #Add title
  gt::cols_label(metric = "Metric",
             group1 = "Group 1",
             group2 = "Group 2",
             n1 = "N1",
             n2 = "N2",
             statistic = "Statistic",
             df = "Df",
             cohens_d = "Cohen's d",
             p.adj = "Adjusted p",
             p.adj.signif = "Significance") %>%
  gt::cols_align(align = "center",
                 columns = dplyr::everything()) %>%
  gt::tab_options(table.width=gt::pct(80)) #increasing table width so that it does not get cropped when saving
                
  
```
### Saving this gt object
```{r}
# Load chromote, needed to save using g
library(chromote)

# Make sure you set your path to Chrome using Sys.setenv(CHROMOTE_CHROME = "path/to/chrome.exe") and check this was correct by running chromote::find_chrome()

# Also, make sure to have a folder called "supplementary" in the "outputs" folder!
## The following line ensures that such folder exists
supp_dir <-  here::here("outputs", "supplementary")
if (!dir.exists(supp_dir)) dir.create(supp_dir, recursive = TRUE)


gt::gtsave(ttest_table,
           filename = "ttest_table.png",
           path = here::here("outputs", "supplementary"),
           vwidth = 1450,
           vheight = 800)
```


## Calculating mean and sd of all timing functions in order to report result of the t-test
```{r}
# Define a function that calculates the mean of each id metric
## Note that this function uses the function style_time, which is already imported in metrics_comparison.Rmd from the file vis_metrics_funs.R

metrics_means <- function(df, df_name) {
  
  # Compute means and sds
  df <- df %>%
    summarise(
      mean_ids_raw = style_time(mean(as.numeric(mean_raw), na.rm = TRUE)),
      sd_ids_raw = style_time(sd(as.numeric(mean_raw), na.rm = TRUE)),
      mean_ids_wrlg = style_time(mean(as.numeric(mean_wrlg), na.rm = TRUE)),
      sd_ids_wrlg = style_time(sd(as.numeric(mean_wrlg), na.rm = TRUE)),
      mean_ids_clusters = style_time(mean(as.numeric(mean_clusters), na.rm = TRUE)),
      sd_ids_clusters = style_time(sd(as.numeric(mean_clusters), na.rm = TRUE))
    )
  
  #Adding col to specify which metric and rename the df
  df$metric <- df_name
  
  return(df)
}

# Now we run a for loop on different metric dfs to calculate the mean 

# Create a named list of data frames
metrics_dfs <- list(
  mlit250_all = mlit250_all,
  mlit1000_all = mlit1000_all,
  llit10_all = llit10_all,
  llit250_all = llit250_all,
  llit1000_all = llit1000_all,
  flit10_all = flit10_all,
  flit250_all = flit250_all,
  flit1000_all = flit1000_all,
  tat1000_all = tat1000_all,
  tat250_all = tat250_all
)

# Initiate empty list to store results
means_metric_list <- list()

# Create for loop 
for (df_name in names(metrics_dfs)) {
 
   df <- metrics_dfs[[df_name]]
  
  # Compute the means for the current data frame
  df_means <- metrics_means(df, df_name)
  
  # Store the resulting data frame in the list, using the index i
  means_metric_list[[df_name]] <- df_means
}

# Convert the list of data frames to a single data frame
means_metrics_df <- bind_rows(means_metric_list)
```

## Calculating mean and sd of is and iv
```{r}
is_means <- is_all %>%
    summarise(
      mean_ids_raw = mean(IS_raw, na.rm = TRUE),
      sd_ids_raw = sd(IS_raw, na.rm = TRUE),
      mean_ids_wrlg = mean(IS_wrlg, na.rm = TRUE),
      sd_ids_wrlg = sd(IS_wrlg, na.rm = TRUE),
      mean_ids_clusters = mean(IS_clusters, na.rm = TRUE),
      sd_ids_clusters = sd(IS_clusters, na.rm = TRUE),
    ) %>%
  mutate(metric = "is")

iv_means <- iv_all %>%
  summarise(
      mean_ids_raw = mean(IV_raw, na.rm = TRUE),
      sd_ids_raw = sd(IV_raw, na.rm = TRUE),
      mean_ids_wrlg = mean(IV_wrlg, na.rm = TRUE),
      sd_ids_wrlg = sd(IV_wrlg, na.rm = TRUE),
      mean_ids_clusters = mean(IV_clusters, na.rm = TRUE),
      sd_ids_clusters = sd(IV_clusters, na.rm = TRUE),
    ) %>%
  mutate(metric = "iv")

```

## Now we would like to have a single table for all metrics.
The issue with this is that bind_rows() will not merge cols that are of different data types (hms and numeric, in our case). Hence, we first convert everything to character, and then combine. We can do this since we are creating this table for display only, and not for any calculations.
```{r}
# Convert means_metrics_df cols to character
means_metrics_df <- means_metrics_df %>%
  mutate(dplyr::across(.fns = as.character))

# Convert numeric cols to character and round to 4 digits
iv_means <- iv_means %>%
  mutate(dplyr::across(where(is.numeric), ~ format(.x, digits = 4)))

# Convert numeric cols to character and round to 4 digits
is_means <- is_means %>%
  mutate(dplyr::across(where(is.numeric), ~ format(.x, digits = 4)))


# Combine the data using bind_rows
means_dfs <- dplyr::bind_rows(means_metrics_df, is_means, iv_means)

# Rename some columns to eliminate the "_all" from the metric col
means_dfs <- means_dfs %>%
  mutate(metric = stringr::str_replace(metric, "_all$", "")) %>%
  dplyr::relocate(metric, .before= mean_ids_raw) # re-order columns so that metric is first one
```

### Create gt table for this dataframe
```{r}
means_table <- means_dfs %>%
  gt::gt() %>%
  gt::tab_header(title = gt::md("**Means and SDs of light exposure metrics (n=12)**")) %>% #Add title
  gt::cols_label(metric = "Metric",
             mean_ids_raw = "Raw dataset (mean)",
             sd_ids_raw = "Raw dataset (SD)",
             mean_ids_wrlg = "Clean (Wear log) dataset (mean)",
             sd_ids_wrlg = "Clean (Wear log) dataset (SD)",
             mean_ids_clusters = "Clean (algorithm) dataset (mean)",
             sd_ids_clusters = "Clean (algorithm) dataset (SD)") %>%
  gt::cols_align(align = "center",
                 columns = dplyr::everything()) 

# Save the gt table
## Make sure you set your path to Chrome using Sys.setenv(CHROMOTE_CHROME = "path/to/chrome.exe") and check this was correct by running chromote::find_chrome()

# AGain, if not already there: make sure you have a folder called "supplementary" in the "outputs" folder!
## The following line ensures that such folder exists
supp_dir <-  here::here("outputs", "supplementary")
if (!dir.exists(supp_dir)) dir.create(supp_dir, recursive = TRUE)

gt::gtsave(means_table,
           filename = "means_table.png",
           path = here::here("outputs", "supplementary"))


```

## Calculating the unstandardised effect size for the significant result, as we need to report this in the paper
```{r}
tat250_unst_effsize <- tat250_all %>%
  summarise(mean = mean(delta_clusters))
```

