---
title: "metrics_stats"
author: "Carolina Guidolin"
date: "2024-12-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Aim
To calculate differences between metrics calculated in the script 06_metrics_comparison.Rmd. Specifically, we will be using a t-test to do this.

## Let's first check the normality of our data
### Import the norm_check functions before running this as well as necessary packages
```{r}
# Function to check normality
base::source(here::here("03_analysis", "functions", "norm_check_funs.R"))

library(afex)
library(ggpubr)
library(rstatix)
```

### Testing for normality of residuals 
```{r}
# Create list of data frames containing metric values
metrics_dfs <- list(
  mlit250_all,
  mlit1000_all,
  llit10_all,
  llit250_all,
  llit1000_all,
  flit10_all,
  flit250_all,
  flit1000_all,
  tat1000_all,
  tat250_all,
  mean_all,
  m10_all
)

# Visualise normality of the means for each df

for (df in metrics_dfs) {

    print(norm_check_means(df))
  
}

## The distribution does not look normal, and for several metrics the Shapiro Wilk test also returns significant results
## Hence, non-parametric alternative is needed

```

### Performing the non-parametric Friedman test for the metrics, and calculate pairwise comparisons (post-hoc tests) using Wilcoxon test 

#### First, we  create a function to perform the two test for all metrics
```{r}
# Friedman test
## First, we create a function for the metrics that have been calculated as average of 6 participation days
## These are: mlit250, mlit1000, llit10, llit250, llit1000, flit10, flit250, flit1000, tat1000, tat250, mean (daytime, M10m)

friedman_and_posthoc <- function(df, pval_threshold = 0.05) {
  
  # Get the name of the input df as a string
  df_name <- deparse(substitute(df))
  
  # Turn into long format
  df_long <- df %>%
    select(Id, mean_raw, mean_wrlg, mean_clusters) %>%
    pivot_longer(cols = c(mean_raw, mean_wrlg, mean_clusters),
                 names_to = "dataset",
                 values_to = "mean") %>%
    mutate(mean = as.numeric(mean),
           Id = as.factor(Id)) %>%
    ungroup()
  
  # Friedman test and effect size (Kendall's W)
  friedman <- df_long %>%
    rstatix::friedman_test(mean ~ dataset | Id) %>%
    mutate(
      kendallsw = rstatix::friedman_effsize(df_long, mean ~ dataset | Id)$effsize,
      metric = df_name
    )
  
  # Initialise empty posthoc variable
  posthoc <- NULL
  
  # Post-hoc only if friedman test is significant
  if (friedman$p < pval_threshold) {
    # Perform Wilcoxon pairwise comparisons
    posthoc <- df_long %>%
      rstatix::pairwise_wilcox_test(
        mean ~ dataset,
        paired = TRUE,
        p.adjust.method = "fdr"
      ) %>%
      # Calculate the effect size for Wilcoxon test
      mutate(
        r = abs(statistic) / sqrt(length(unique(df_long$Id))),
        metric = df_name # add metric name
    )
  } 
  
  list(friedman = friedman, posthoc = posthoc)
}

# Helper function to combine results
combine_friedman_posthoc <- function(results_list) {
  
  friedman_all <- purrr::map_dfr(results_list, "friedman")
  posthoc_all <- purrr::map_dfr(results_list, "posthoc", .id = "metric_source")
  
  list(friedman_all = friedman_all, posthoc_all = posthoc_all)
}
```

```{r}
library(purrr)

metrics_list <- list(
  mlit250_all,
  mlit1000_all,
  llit10_all,
  llit250_all,
  llit1000_all,
  flit10_all,
  flit250_all,
  flit1000_all,
  tat1000_all,
  tat250_all,
  mean_all,
  m10_all
)

results <- map(metrics_list, friedman_and_posthoc)

combined <- combine_friedman_posthoc(results)

# All Friedman test results together:
combined$friedman_all

# All Wilcoxon posthoc results together (only significant metrics):
combined$posthoc_all

```


#### Applying the function to the metrics dfs
```{r}

#MLiT250
mlit250_friedman <- friedman_and_posthoc(mlit250_all)

# MLiT1000
mlit1000_friedman <- friedman_test_perform(mlit1000_all)

# FLitT 10
flit10_friedman <- friedman_test_perform(flit10_all)

#FLitT250
flit250_friedman <- friedman_test_perform(flit250_all)

#FLiT1000
flit1000_friedman <- friedman_test_perform(flit1000_all)

# LLitT 10
llit10_friedman <- friedman_test_perform(llit10_all)

# LLitT 250
llit250_friedman <- friedman_test_perform(llit250_all)

# LLitT 1000
llit1000_friedman <- friedman_test_perform(llit1000_all)

# TAT 250
tat250_friedman <- friedman_test_perform(tat250_all)

# TAT 1000
tat1000_friedman <- friedman_test_perform(tat1000_all)

# Daily average
mean_friedman <- friedman_and_posthoc(mean_all)

#M10m
m10_friedman <- friedman_test_perform(m10_all)


```

### Peform Friedman test on remaining metrics (IV and IS)
```{r}
# Turning into long format

# IV
iv_means_long <- iv_all %>%
  pivot_longer(cols = c(IV_raw, IV_wrlg, IV_clusters),
               names_to = "dataset",
               values_to = "mean") %>%
  select(-c(delta_wrlg, delta_clusters)) %>%
  mutate(mean = as.numeric(mean),
         Id = as.factor(Id))

# IS
is_means_long <- is_all %>%
  pivot_longer(cols = c(IS_raw, IS_wrlg, IS_clusters),
               names_to = "dataset",
               values_to = "mean") %>%
  select(-c(delta_wrlg, delta_clusters))  %>%
  mutate(mean = as.numeric(mean),
         Id = as.factor(Id))


# Performing test

# IV
iv_friedman <- iv_means_long %>%
    rstatix::friedman_test(mean ~ dataset | Id) %>%
    mutate(metric = "iv") 

iv_kendallsw <- iv_means_long %>%
  rstatix::friedman_effsize(mean ~ dataset | Id) 

iv_friedman <- iv_friedman %>%
  mutate(
    kendallsw = iv_kendallsw$effsize
  )

# IS
is_friedman <- is_means_long %>%
    rstatix::friedman_test(mean ~ dataset | Id) %>%
    mutate(metric = "is") 

is_kendallsw <- is_means_long %>%
  rstatix::friedman_effsize(mean ~ dataset | Id) 

is_friedman <- is_friedman %>%
  mutate(
    kendallsw = is_kendallsw$effsize
  )



#Combining all dfs into one
friedmantest_all <- dplyr::bind_rows(mlit250_friedman,
                              mlit1000_friedman,
                              flit10_friedman,
                              flit250_friedman,
                              flit1000_friedman,
                              llit10_friedman,
                              llit250_friedman,
                              llit1000_friedman,
                              tat250_friedman,
                              tat1000_friedman,
                              mean_friedman,
                              m10_friedman,
                              iv_friedman,
                              is_friedman)
```

### Post-hoc pairwise comparisons

Identify which metrics have significant p values
```{r}
# Identify which metrics have significant Friedman p-values
significant_metrics <- friedmantest_all %>%
  filter(p < 0.05) %>%
  pull(metric)

print(significant_metrics)

```
Create function to perform post-hoc tests
```{r}
wilcoxon_posthoc <- function (df) {
  
  # Get the name of the input df as a string
  df_name <- deparse(substitute(df))
  
# Turning df into long form to perform computations
  df_long <- df %>%
  select(Id, mean_raw, mean_wrlg, mean_clusters) %>%
  pivot_longer(cols = c(mean_raw, mean_wrlg, mean_clusters),
               names_to = "dataset",
               values_to = "mean")
  
  # Turn mean column to numeric (seconds) for the duration and timing metrics
  # for daytime average and M10m, it is already numeric
  df_long <- df_long %>%
    mutate(mean = as.numeric(mean),
    Id = as.factor(Id)
    ) %>%
    ungroup() # need to ungroup for the test to be performed correctly
  
  # Pairwise Wilcoxon signed-rank test
  posthoc <- df_long %>%
    rstatix::pairwise_wilcox_test(
      mean ~ dataset,
      paired = TRUE,
      p.adjust.method = "fdr"
    )
  
  posthoc <- posthoc %>%
    mutate(metric = metric_name)
  
  return(posthoc)
}

```

Apply to each metric that had a significant result
```{r}
# Update metrics_dfs to include iv and is
metric_dfs <- list(
  mlit250 = mlit250_all,
  mlit1000 = mlit1000_all,
  flit10 = flit10_all,
  flit250 = flit250_all,
  flit1000 = flit1000_all,
  llit10 = llit10_all,
  llit250 = llit250_all,
  llit1000 = llit1000_all,
  tat250 = tat250_all,
  tat1000 = tat1000_all,
  mean = mean_all,
  m10 = m10_all,
  iv = iv_all,
  is = is_all
)

# Run post-hoc for significant ones
posthoc_results <- purrr::map_dfr(significant_metrics, function(metric) {
  df <- metric_dfs[[metric]]
  wilcoxon_posthoc(df, metric)
})

# View results
posthoc_results

```


```{r}
# Apply multiple corrections
ttest_final <- ttest_all %>% 
  mutate(p.adj = stats::p.adjust(p,
                           "fdr", # we choose FDR (or BH - same thing) as method
                           n=length(p))) %>% # we want to correct for all comparisons, i.e. n=36
  rstatix::add_significance("p.adj") %>%
  dplyr::relocate(metric, .before= .y.) # re-order columns

# Rename some columns to eliminate the "_all" from the metric col
ttest_final <- ttest_final %>%
  mutate(metric = stringr::str_replace(metric, "_all$", ""))
```

## Turning this into a gt table
```{r}
ttest_table <- ttest_final %>%
  select(-c(.y., p.signif)) %>% #we do not need this col in the final summary
  gt::gt() %>%
  gt::tab_header(title = gt::md("**T-test results**")) %>% #Add title
  gt::cols_label(metric = "Metric",
             group1 = "Group 1",
             group2 = "Group 2",
             n1 = "N1",
             n2 = "N2",
             statistic = "Statistic",
             df = "Df",
             cohens_d = "Cohen's d",
             p.adj = "Adjusted p",
             p.adj.signif = "Significance") %>%
  gt::cols_align(align = "center",
                 columns = dplyr::everything()) %>%
  gt::tab_options(table.width=gt::pct(80)) #increasing table width so that it does not get cropped when saving
                
  
```
### Saving this gt object
```{r}
# Load chromote, needed to save using g
library(chromote)

# Make sure you set your path to Chrome using Sys.setenv(CHROMOTE_CHROME = "path/to/chrome.exe") and check this was correct by running chromote::find_chrome()

# Also, make sure to have a folder called "supplementary" in the "outputs" folder!
## The following line ensures that such folder exists
supp_dir <-  here::here("outputs", "supplementary")
if (!dir.exists(supp_dir)) dir.create(supp_dir, recursive = TRUE)


gt::gtsave(ttest_table,
           filename = "ttest_table.png",
           path = here::here("outputs", "supplementary"),
           vwidth = 1450,
           vheight = 800)
```


## Calculating mean and sd of all timing functions in order to report result of the t-test
```{r}
# Define a function that calculates the mean of each id metric
## Note that this function uses the function style_time, which is already imported in metrics_comparison.Rmd from the file vis_metrics_funs.R

metrics_means <- function(df, df_name) {
  
  # Compute means and sds
  df <- df %>%
    summarise(
      mean_ids_raw = style_time(mean(as.numeric(mean_raw), na.rm = TRUE)),
      sd_ids_raw = style_time(sd(as.numeric(mean_raw), na.rm = TRUE)),
      mean_ids_wrlg = style_time(mean(as.numeric(mean_wrlg), na.rm = TRUE)),
      sd_ids_wrlg = style_time(sd(as.numeric(mean_wrlg), na.rm = TRUE)),
      mean_ids_clusters = style_time(mean(as.numeric(mean_clusters), na.rm = TRUE)),
      sd_ids_clusters = style_time(sd(as.numeric(mean_clusters), na.rm = TRUE))
    )
  
  #Adding col to specify which metric and rename the df
  df$metric <- df_name
  
  return(df)
}

# Now we run a for loop on different metric dfs to calculate the mean 

# Create a named list of data frames
metrics_dfs <- list(
  mlit250_all = mlit250_all,
  mlit1000_all = mlit1000_all,
  llit10_all = llit10_all,
  llit250_all = llit250_all,
  llit1000_all = llit1000_all,
  flit10_all = flit10_all,
  flit250_all = flit250_all,
  flit1000_all = flit1000_all,
  tat1000_all = tat1000_all,
  tat250_all = tat250_all
)

# Initiate empty list to store results
means_metric_list <- list()

# Create for loop 
for (df_name in names(metrics_dfs)) {
 
   df <- metrics_dfs[[df_name]]
  
  # Compute the means for the current data frame
  df_means <- metrics_means(df, df_name)
  
  # Store the resulting data frame in the list, using the index i
  means_metric_list[[df_name]] <- df_means
}

# Convert the list of data frames to a single data frame
means_metrics_df <- bind_rows(means_metric_list)
```

## Calculating mean and sd of is and iv
```{r}
is_means <- is_all %>%
    summarise(
      mean_ids_raw = mean(IS_raw, na.rm = TRUE),
      sd_ids_raw = sd(IS_raw, na.rm = TRUE),
      mean_ids_wrlg = mean(IS_wrlg, na.rm = TRUE),
      sd_ids_wrlg = sd(IS_wrlg, na.rm = TRUE),
      mean_ids_clusters = mean(IS_clusters, na.rm = TRUE),
      sd_ids_clusters = sd(IS_clusters, na.rm = TRUE),
    ) %>%
  mutate(metric = "is")

iv_means <- iv_all %>%
  summarise(
      mean_ids_raw = mean(IV_raw, na.rm = TRUE),
      sd_ids_raw = sd(IV_raw, na.rm = TRUE),
      mean_ids_wrlg = mean(IV_wrlg, na.rm = TRUE),
      sd_ids_wrlg = sd(IV_wrlg, na.rm = TRUE),
      mean_ids_clusters = mean(IV_clusters, na.rm = TRUE),
      sd_ids_clusters = sd(IV_clusters, na.rm = TRUE),
    ) %>%
  mutate(metric = "iv")

```

## Now we would like to have a single table for all metrics.
The issue with this is that bind_rows() will not merge cols that are of different data types (hms and numeric, in our case). Hence, we first convert everything to character, and then combine. We can do this since we are creating this table for display only, and not for any calculations.
```{r}
# Convert means_metrics_df cols to character
means_metrics_df <- means_metrics_df %>%
  mutate(dplyr::across(.fns = as.character))

# Convert numeric cols to character and round to 4 digits
iv_means <- iv_means %>%
  mutate(dplyr::across(where(is.numeric), ~ format(.x, digits = 4)))

# Convert numeric cols to character and round to 4 digits
is_means <- is_means %>%
  mutate(dplyr::across(where(is.numeric), ~ format(.x, digits = 4)))


# Combine the data using bind_rows
means_dfs <- dplyr::bind_rows(means_metrics_df, is_means, iv_means)

# Rename some columns to eliminate the "_all" from the metric col
means_dfs <- means_dfs %>%
  mutate(metric = stringr::str_replace(metric, "_all$", "")) %>%
  dplyr::relocate(metric, .before= mean_ids_raw) # re-order columns so that metric is first one
```

### Create gt table for this dataframe
```{r}
means_table <- means_dfs %>%
  gt::gt() %>%
  gt::tab_header(title = gt::md("**Means and SDs of light exposure metrics (n=12)**")) %>% #Add title
  gt::cols_label(metric = "Metric",
             mean_ids_raw = "Raw dataset (mean)",
             sd_ids_raw = "Raw dataset (SD)",
             mean_ids_wrlg = "Clean (Wear log) dataset (mean)",
             sd_ids_wrlg = "Clean (Wear log) dataset (SD)",
             mean_ids_clusters = "Clean (algorithm) dataset (mean)",
             sd_ids_clusters = "Clean (algorithm) dataset (SD)") %>%
  gt::cols_align(align = "center",
                 columns = dplyr::everything()) 

# Save the gt table
## Make sure you set your path to Chrome using Sys.setenv(CHROMOTE_CHROME = "path/to/chrome.exe") and check this was correct by running chromote::find_chrome()

# AGain, if not already there: make sure you have a folder called "supplementary" in the "outputs" folder!
## The following line ensures that such folder exists
supp_dir <-  here::here("outputs", "supplementary")
if (!dir.exists(supp_dir)) dir.create(supp_dir, recursive = TRUE)

gt::gtsave(means_table,
           filename = "means_table.png",
           path = here::here("outputs", "supplementary"))


```

## Calculating the unstandardised effect size for the significant result, as we need to report this in the paper
```{r}
tat250_unst_effsize <- tat250_all %>%
  summarise(mean = mean(delta_clusters))
```

