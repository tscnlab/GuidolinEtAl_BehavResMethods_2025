---
title: "nonwear_source_fusion"
author: "Carolina Guidolin"
date: "2023-11-21"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Backgorund
The aim is to describe and compare strategies for tracking non-wear time of wearable light loggers used in ambulatory light exposure studies. This can help other researchers to plan their experiments and choose a non-wear time strategy which fits their research requirements. 

##Dataset description
Participants N = 26
Duration: 7 full days
Wearable device: ActLumus with 10 seconds sampling period, worn on spectacles ("light glasses")

Non-wear time information is given by three sources:  
1. Wear log completed by the participant with following information: 
  - Timestamp of taking the light glasses off (current/retrospective) 
  - Timestamp of placing the light glasses back on (current/retrospective) 
  - Timestamp of taking the light glasses off before bed (current/retrospective) 
  - Use of black bag during non-wear episode (current/retrospective) 

2. Button presses done by the participant (logged by ActLumus); 

3. Light while in black bag (mEDI ≤1 lux during non-wear time) 
  - Note: this is partly related to the Wear log, as information on whether the black bag was used or not is contained in the Wear log 

Each of these three sources can be used individually to detect a non-wear period. However, the Wear log entries were monitored twice a day by the experimenter, and thus considered as the “ground truth” for non-wear detection. 

## Research question
The ovearching RQ is: What is the concordance between different sources of non-wear?

##Data fusion 
To answer the RQ, we first need to integrate the data coming from these three sources. We will do this in a LightLogR native format, as in the future we might want to have these functions built in LightLogR.

###Load in the necessary packages
```{r}
library(tidyverse)
library(hms)
library(here)
library(scales)
library(lubridate)
library(LightLogR)
library(ggpubr)
library(ggbreak)
```


### Loading actlumus data 
First, we need to import the ActLumus file where the button press information is contained. We will need this later.
```{r}
Sys.setlocale("LC_TIME", "en_US.UTF-8") #needed to run this code to have the days displayed in English and not German

path <- "G:/cyepi/code/pre-processing/nonwear_detection/actlumus"
tz <- "Europe/Berlin"

# Get a list of file paths in the specified directory
actlumusfiles <- list.files(path, pattern = ".txt", full.names = TRUE)

# Create an empty dataframe to store the combined data
dataset.LL.all <- data.frame()

# Iterate over each file and import data
# Ensure that the datasets crossing from DST to ST on 29.10.2023 are adjusted for using dst_adjustment function 
dataset.LL.all <- import$ActLumus(actlumusfiles, tz = tz, auto.id = "^(\\d{3})", dst_adjustment = TRUE)

```

Every participant started at different times. We will have to specify start and end time manually. 
Start times are taken as the first timestamp when the participant started the study. This is reported in the Wear log.
End times are taken as the timestamp of "putting the light glasses back on" on the morning of the last day of the experiment, i.e. when participants had to return to the laboratory. In case this was missing, "data"out of bed" data from the sleep diary was used (this was the case for 4 participants), as this would be the closest approximation. For one participant (213), the data from the sleep diary was missing as well. Thus, the end time was determined as midnight of the last experimental day (Sunday).

```{r}
filtered_time <- data.frame(
  Id = c("201", "202", "204", "205", "206", "208", "209", "210", "212", "213", "214", "215", "216", "218", "219", "221", "222", "223", "224", "225", "226", "227", "228", "229", "230", "231"),
  start = as.POSIXct(c("2023-08-14 12:40:00", "2023-08-14 13:26:00", "2023-08-14 14:43:00", "2023-08-28 15:42:00", "2023-08-28 14:16:00", "2023-09-04 12:36:00", "2023-09-04 14:01:00", "2023-09-04 15:20:00", "2023-09-11 13:03:00", "2023-09-11 15:06:00", "2023-09-25 14:56:00", "2023-10-02 11:30:00", "2023-10-02 14:31:00", "2023-10-16 11:18:00", "2023-10-16 12:40:00", "2023-10-23 11:22:00", "2023-10-23 13:10:00", "2023-10-30 11:34:00", "2023-10-30 13:24:00", "2023-10-30 15:05:00", "2023-10-30 16:34:00", "2023-10-30 17:44:00", "2023-11-06 11:02", "2023-11-06 12:34", "2023-11-06 14:02", "2023-11-06 17:12" )),    # Add start times
  end = as.POSIXct(c("2023-08-20 23:59:59", "2023-08-20 23:59:59", "2023-08-20 23:59:59", "2023-09-03 23:59:59", "2023-09-03 23:59:59", "2023-09-10 23:59:59", "2023-09-10 23:59:59", "2023-09-10 23:59:59", "2023-09-17 23:59:59", "2023-09-17 23:59:59", "2023-10-01 23:59:59", "2023-10-08 23:59:59", "2023-10-08 23:59:59", "2023-10-22 23:59:59" , "2023-10-22 23:59:59", "2023-10-29 23:59:59", "2023-10-29 23:59:59", "2023-11-05 23:59:59", "2023-11-05 23:59:59", "2023-11-05 23:59:59", "2023-11-05 23:59:59", "2023-11-05 23:59:59", "2023-11-12 23:59:59", "2023-11-12 23:59:59", "2023-11-12 23:59:59", "2023-11-12 23:59:59"))            # Add end times
)
```


```{r}
filtered_time <- data.frame(
  Id = c("201", "202", "204", "205", "206", "208", "209", "210", "212", "213", "214", "215", "216", "218", "219", "221", "222", "223", "224", "225", "226", "227", "228", "229", "230", "231"),
  start = as.POSIXct(c("2023-08-14 12:40:00", #201
                       "2023-08-14 13:26:00", #202
                       "2023-08-14 14:43:00", #204
                       "2023-08-28 15:42:00", #205
                       "2023-08-28 14:16:00", #206
                       "2023-09-04 12:36:00", #208
                       "2023-09-04 14:01:00", #209
                       "2023-09-04 15:20:00", #210
                       "2023-09-11 13:03:00", #212
                       "2023-09-11 15:06:00", #213
                       "2023-09-25 14:56:00", #214
                       "2023-10-02 11:30:00", #215
                       "2023-10-02 14:31:00", #216
                       "2023-10-16 11:18:00", #218
                       "2023-10-16 12:40:00", #219
                       "2023-10-23 11:22:00", #221
                       "2023-10-23 13:10:00", #222
                       "2023-10-30 11:34:00", #223
                       "2023-10-30 13:24:00", #224
                       "2023-10-30 15:05:00", #225
                       "2023-10-30 16:34:00", #226
                       "2023-10-30 17:44:00", #227
                       "2023-11-06 11:02:00", #228
                       "2023-11-06 12:34:00", #229
                       "2023-11-06 14:02:00", #230
                       "2023-11-06 17:12:00"  #231
                       )),    # Add start times
  end = as.POSIXct(c("2023-08-21 07:31:00", #201
                     "2023-08-21 07:23:00", #202
                     "2023-08-21 08:59:00", #204
                     "2023-09-04 07:28:00", #205
                     "2023-09-04 08:08:00", #206
                     "2023-09-11 07:30:00", #208
                     "2023-09-11 07:45:00", #209
                     "2023-09-11 06:16:00", #210 from sleep diary, out_ofbed
                     "2023-09-18 06:01:00", #212 
                     "2023-09-17 23:59:59", #213 midnight of previous day, because of missing data on final day 
                     "2023-10-02 09:02:00", #214
                     "2023-10-09 08:27:00", #215
                     "2023-10-09 11:01:00", #216
                     "2023-10-23 08:13:00", #218
                     "2023-10-23 07:10:00", #219 from sleep diary, out_ofbed
                     "2023-10-30 07:58:00", #221
                     "2023-10-30 08:18:00", #222
                     "2023-11-06 08:00:00", #223
                     "2023-11-06 08:23:00", #224
                     "2023-11-06 05:44:00", #225 from sleep diary, out_ofbed
                     "2023-11-06 06:49:00", #226
                     "2023-11-06 07:07:00", #227
                     "2023-11-13 07:49:00", #228
                     "2023-11-13 07:09:00", #229
                     "2023-11-13 08:02:00", #230 from sleep diary, out_ofbed
                     "2023-11-13 08:15:00" #231
                     ))# Add end times
)

#Adjust the dataset 
dataset.LL.all <- dataset.LL.all %>%
  inner_join(filtered_time, by = "Id") %>%
  filter(Datetime >= start, Datetime <= end) %>%
  select(-start, -end)

```

### Loading Wear log files 

First, we need to import the data from the wear log
```{r}
filepath <- here("G:/cyepi/code/pre-processing/nonwear_detection/wearlog")

# Get the files names from directory
wearlogfiles = list.files(filepath, pattern="*.csv", full.names = TRUE)

```

### Non-wear time according to the Wear log (1st source of non-wear)
Here we create States (using import_Statechanges) that code for the 3 most important information contained in the Wear log: 1. When the light glasses were on, 2. When the light glasses were off, 3. When the light glasses were put off for sleep. Retrospective and real-time information are treated as equal for this step. 
```{r pressure, echo=FALSE}
wearlog_intervals <- 
  #filenames:
  wearlogfiles %>% 
  #import_Statechanges from LightLogR to create states based on timestamps
  LightLogR::import_Statechanges(
    sep = ";", dec = ",", Datetime.format = "dmyHM", tz = "Europe/Berlin", 
    Id.colname = record_id,
    State.colnames = 
      c("wearlog_on", "wearlog_off", "wearlog_past_on", "wearlog_past_off", "wearlog_bed", "wearlog_past_sleep"),
    State.encoding = 
      c("1", "0", "1", "0", "2", "2") #off coded as 0, on coded as 1, sleep coded as 2
    ) 

```

###Quality check 1a: Identifying consecutive datetimes
The first thing that we want to check is for identical consecutive timestamps. These should not occur, but it is possible that something went "wrong" from the participants' side. If this is the case, it should be corrected. 
```{r}
error_messages_datetime <- character(0) # We create an empty vector where we can store the errors

wearlog_intervals %>%
  group_by(Id) %>%
  arrange(Datetime) %>%  # Ensure data is sorted by Datetime
  mutate(PrevDatetime = lag(Datetime)) %>%
  filter(Datetime == PrevDatetime) %>%
  ungroup() %>%
  rowwise() %>%
  mutate(error_message = paste("Consecutive timestamps at record_id:", Id, "datetime:", Datetime)) %>%
  pull(error_message) -> error_messages_datetime

# Check if there are error messages
if (length(error_messages_datetime) > 0) {
  # There are errors; print the error messages
  for (error_message in error_messages_datetime) {
    cat("Error:", error_message, "\n")
  }
} else {
  cat("No consecutive value errors found.")
}

#1Error: Consecutive timestamps at record_id: 202 datetime: 2023-08-14 16:42:00, wearlog_on (1) - participant accidentally entered previous datetime. Correct value can be taken from start_date column: 14-08-2023 17:11:00

corrected_202datetime_on <- as.POSIXct("2023-08-14 17:11:00", format = "%Y-%m-%d %H:%M:%S", tz = tz)

wearlog_intervals <- wearlog_intervals %>%
  mutate(
    Datetime = if_else(Id == "202" & Datetime == "2023-08-14 16:42:00" & State == 1, corrected_202datetime_on, Datetime))

#2Error: Consecutive timestamps at record_id: 202 datetime: 2023-08-14 22:22:00 wearlog_on (1) - participant accidentally entered previous datetime. Correct value can be taken from start_date column: 15-08-2023 07:47:00

corrected_202datetime_on1 <- as.POSIXct("2023-08-15 07:47:00", format = "%Y-%m-%d %H:%M:%S", tz = tz)

wearlog_intervals <- wearlog_intervals %>%
  mutate(
    Datetime = if_else(Id == "202" & Datetime == "2023-08-14 22:22:00" & State == 1, corrected_202datetime_on1, Datetime)) %>%
  filter(!(Id == "202" & Datetime == "2023-08-14 22:21:00" & State == 0)) # We noticed that the participant forgot that the "sleep" option existed, so they logged wearlog_off when going to bed. One minute after they remember and then logged it as wearlog_bed. So we will eliminate this wearlog_off entry, since it is redudant with the following wearlog_bed entry. 


#3Error: Consecutive timestamps at record_id: 201 datetime: 2023-08-17 06:51:00 wearlog_off (0) - participant wore the light logger for less than 1 minute, and then placed it in the black bag. To adjust for this, we will add 1 minute to the wear log entry: 2023-08-17 06:52:00

corrected_201datetime_off <- as.POSIXct("2023-08-17 06:52:00", format = "%Y-%m-%d %H:%M:%S", tz = tz)

wearlog_intervals <- wearlog_intervals %>%
  mutate(
    Datetime = if_else(Id == "201" & Datetime == "2023-08-17 06:51:00" & State == 0, corrected_201datetime_off, Datetime))


#4Error: Consecutive timestamps at record_id: 201 datetime: 2023-08-17 17:40:00 wearlog_on (1) - participant accidentally entered incorrect datetime. Correct value can be taken from start_date column: 17-08-2023 11:40:00

corrected_201datetime_off1 <- as.POSIXct("2023-08-17 11:40:00", format = "%Y-%m-%d %H:%M:%S", tz = tz)

wearlog_intervals <- wearlog_intervals %>%
  mutate(
    Datetime = if_else(Id == "201" & Datetime == "2023-08-17 17:40:00" & State == 1, corrected_201datetime_off1, Datetime))

#5Error: Consecutive timestamps at record_id: 201 datetime: 2023-08-20 11:19:00 wearlog_bed (2) - participant accidentally entered incorrect datetime. Correct value can be taken from start_date column: 2023-08-20 01:11:00

corrected_201datetime_bed <- as.POSIXct("2023-08-20 01:11:00", format = "%Y-%m-%d %H:%M:%S", tz = tz)

wearlog_intervals <- wearlog_intervals %>%
  mutate(
    Datetime = if_else(Id == "201" & Datetime == "2023-08-20 11:19:00" & State == 2, corrected_201datetime_bed, Datetime))


#6Error: Consecutive timestamps at record_id: 205 datetime: 2023-08-28 15:42:00 wearlog_on (1) - first entry for participant was accidentally entered twice. One of them should be removed. 
wearlog_intervals_c <- wearlog_intervals %>%
  group_by(Id) %>%
  filter(!(Id == "205" & row_number() == 1)) %>%
  ungroup()


#7Error: Consecutive timestamps at record_id: 208 datetime: 2023-09-08 07:33:00 wearlog_on (1) - entry for participant was accidentally entered twice. One of them should be removed. 

participant_id <- "208"
duplicate_datetime <- as.POSIXct("2023-09-08 07:33:00", format = "%Y-%m-%d %H:%M:%S", tz = tz)
duplicate_state <- 1

wearlog_intervals_d <- wearlog_intervals_c %>%
  group_by(Id) %>%
  mutate(duplicate_flag = cumsum(Id == participant_id & Datetime == duplicate_datetime & State == duplicate_state)) %>% #creating a second column which will have value of 2 if a duplicate occurs
  filter(!(Id == participant_id & Datetime == duplicate_datetime & State == duplicate_state & duplicate_flag == 2)) %>% #filters out second occurrence of the entry
  select(-duplicate_flag) %>% #removes extra column
  ungroup()


#8Error: Consecutive timestamps at record_id: 214 datetime: 2023-09-26 23:15:00 wearlog off (0) - entry for participant was accidentally entered twice. The second one is a wearlog_bed entry, which participant specified being the correct one in email exchange. This, the wearlog_off entry should be removed. 

wearlog_intervals_e <- wearlog_intervals_d %>%
  filter(!(Id == "214" & Datetime == "2023-09-26 23:15:00" & State == 0))
```
##Summary of the rules used to adjust for identical consecutive datetimes
1) If consecutive identical datetime, but different States, and start_date different = take info from start_date [this is an automated timestamp from the app]
2) If consecutive identical datetime, and same States, and same start_date timestamp = keep the first one [second entry considered accidental]
3) If consecutive identical datetime, and different States, and same start_date timestamp, and consecutive value suggests it is a wrong entry = adjust accordingly (see solution 3 and 8), with the help of visual inspection 

###Quality check 1b: verifying that the quality check worked. We apply the same code, with the refined dataset. Expected result is that we do not see any consecutive datetime values.
```{r}
error_messages_datetime <- character(0) # We create an empty vector where we can store the errors

wearlog_intervals_e %>%
  group_by(Id) %>%
  arrange(Datetime) %>%  # Ensure data is sorted by Datetime
  mutate(PrevDatetime = lag(Datetime)) %>%
  filter(Datetime == PrevDatetime) %>%
  ungroup() %>%
  rowwise() %>%
  mutate(error_message = paste("Consecutive timestamps at record_id:", Id, "datetime:", Datetime)) %>%
  pull(error_message) -> error_messages_datetime

# Check if there are error messages
if (length(error_messages_datetime) > 0) {
  # There are errors; print the error messages
  for (error_message in error_messages_datetime) {
    cat("Error:", error_message, "\n")
  }
} else {
  cat("No consecutive value errors found.")
}

#No consecutive values found. Great!
```
###Quality check 2a: Identifying consecutive States
The second thing that we want to check is for identical consecutive States - just like for datetimes, it would not make sense to have two consecutive states. So let's check if we find any. 
```{r}
error_messages_states <- character(0) # We create an empty vector where we can store the errors

# Group by ID and then apply the quality check within each group
wearlog_intervals_e %>%
  group_by(Id) %>%
  arrange(Datetime) %>%  # Ensure data is sorted by Datetime
  mutate(PrevState = lag(State)) %>%
  filter(State == PrevState) %>%
  ungroup() %>%
  rowwise() %>%
  mutate(error_message = paste("Consecutive values at record_id:", Id, "datetime:", Datetime, "state:", State)) %>%
  pull(error_message) -> error_messages_states

# Check if there are error messages
if (length(error_messages_states) > 0) {
  # There are errors; print the error messages
  for (error_message in error_messages_states) {
    cat("Error:", error_message, "\n")
  }
} else {
  cat("No consecutive value errors found.")
}
```
###Quality check 2b: fixing the consecuitve State entries found above
```{r}
#1Error: Consecutive values at record_id: 202 datetime: 2023-08-15 07:47:00 state: 1 
#1solution: This is the same entry that caused issues in the Datetime. We had changed it above to a "wearlog_on" entry, which seems the first entry after the participant has woken up. Since I had not noticed the consecutive datetime error above, I had asked the participant to make a retrospective entry, as I thought that this wearlog_on entry was missing. Now, we eliminate the retrospective entry since we have found the original "current" entry, on the basis that the restropsective entry would be less accurate. 

wearlog_intervals_f <- wearlog_intervals_e %>%
  filter(!(Id == "202" & Datetime == "2023-08-15 07:47:00" & State == 1))

#2Error: Consecutive values at record_id: 201 datetime: 2023-08-18 19:54:00 state: 0. 
#2Solution: This should be a wearlog_on entry. We assume this because of two reasons: 1) visual inspection of light and activity suggests a wear interval between 19:54 and 20:14, and 2) this wearlog_off entry is located between two wearlog_off entries, which suggests that the participant accidentally logged this one as an "off" as well. 

correct_state201 <- "1"
wearlog_intervals_e <- wearlog_intervals_e %>%
  mutate(
    State = if_else(Id == "201" & Datetime == "2023-08-18 19:54:00" & State == 0, correct_state201, State))


#3Error: Consecutive values at record_id: 201 datetime: 2023-08-18 20:14:00 state: 0 
#3solution: this has been fixed with the solution above (#2solution)

#4Error: Consecutive values at record_id: 202 datetime: 2023-08-18 22:29:00 state: 2 
#4solution: This is missing data: the participant did not report any other entry on that day, so the previous entry is the "wearlog_bed" from the night before. To obtain a "wearlog_entry" for this participant, we insert the timestamp from the sleep diary, namely from the column "outof_bed"

newrow_202 <- data.frame(
  Id = as.factor(202),
  State = as.character(1),
  Datetime = as.POSIXct("2023-08-18 06:37:00", tz = tz)
)

wearlog_intervals_g <- bind_rows(wearlog_intervals_f, newrow_202)


#5Error: Consecutive values at record_id: 205 datetime: 2023-09-02 16:47:00 state: 1
#5solution: This should be a wearlog_off entry. We assume this because of two reasons: 1) visual inspection of light and activity suggests a non-wear interval between 16:47 and  17:10, and 2) this wearlog_onentry is located between two wearlog_on entries, which suggests that the participant accidentally logged this one as an "on" as well. 

correct_state205 <- "0"
wearlog_intervals_h <- wearlog_intervals_g %>%
  mutate(
    State = if_else(Id == "205" & Datetime == "2023-09-02 16:47:00" & State == 1, correct_state205, State))  

#6Error: Consecutive values at record_id: 205 datetime: 2023-09-02 17:10:00 state: 1 
#6solution: this has been fixed with the solution above (#5solution)

#7Error: Consecutive values at record_id: 205 datetime: 2023-09-03 09:40:00 state: 1 
#7solution. After visually inspecting the raw light and activity data, as well as looking at the wear log entries, we conclude that this entry is correct. However, there is a problem with the previous entry: record_id: 205 datetime: 2023-09-03 08:40:00 state: 1. It looks like two entries were logged at the same time, which should not be possible in the app. We don't know how this happened, but we will adjust the entries as follows:
#1) 2023-09-03 08:47:00 wearlog_on should be turned into 2023-09-03 08:40:00 wearlog_on 
#2) 2023-09-03 08:40:00 wearlog_on should be turned into 2023-09-03 08:47:00 wearlog_off
#3) 2023-09-03 09:40:00 wearlog_off  shoud be left as is

#1)
correct_state205_1 <- "1"
wearlog_intervals_i <- wearlog_intervals_h %>%
  mutate(
    State = if_else(Id == "205" & Datetime == "2023-09-03 08:40:00" & State == 0, correct_state205_1, State))  

#2)
correct_state205_2 <- "0"

wearlog_intervals_j <- wearlog_intervals_i %>%
  mutate(
    State = if_else(Id == "205" & Datetime == "2023-09-03 08:47:00" & State == 1, correct_state205_2, State)
  )

#8Error: Consecutive values at record_id: 209 datetime: 2023-09-08 00:58:00 state: 2 
#8solution: strangely, the participant thought that they had not logged this, and so they logged it retrsopectively again on the following day. We keep the original entry and eliminate this one. 
wearlog_intervals_k <- wearlog_intervals_j %>%
  filter(!(Id == "209" & Datetime == "2023-09-08 00:30:00" & State == 2))

#9Error: Consecutive values at record_id: 215 datetime: 2023-10-03 08:33:00 state: 1 
#9solution: the participant accidentally entered the previous date (2023-10-03) instead of the current date (2023-10-04). We can change this manually
correct_date_215 <- as.POSIXct("2023-10-04 08:33:00", format = "%Y-%m-%d %H:%M:%S", tz = tz)

wearlog_intervals_m <- wearlog_intervals_k %>%
  mutate(
    Datetime = if_else(Id == "215" & Datetime == "2023-10-03 08:33:00" & State == 1, correct_date_215, Datetime )
  )

#10Error: Consecutive values at record_id: 215 datetime: 2023-10-07 01:15:00 state: 2 
#10solution: the participant forgot to update the date to the next day, since the timestamp is after midnight
correct_date_215_2 <- as.POSIXct("2023-10-08 01:15:00", format = "%Y-%m-%d %H:%M:%S", tz = tz)
wearlog_intervals_n <- wearlog_intervals_m %>%
  mutate(
    Datetime = if_else(Id == "215" & Datetime == "2023-10-07 01:15:00" & State == 2, correct_date_215_2, Datetime )
  )

#11Error: Consecutive values at record_id: 215 datetime: 2023-10-07 16:50:00 state: 1 
#11solution: We do not know why this participant entered this wearlog_on retrospectively. Since there is no strong evidence from visual inspection of light and activity data that they are not wearing the device, we eliminate this entry and keep the previous wearlog_on entry at 12:22

wearlog_intervals_o <- wearlog_intervals_n %>%
  filter(!(Id == "215" & Datetime == " 2023-10-07 16:50:00" & State == 1))

#12Error: Consecutive values at record_id: 218 datetime: 2023-10-21 02:15:00 state: 2 
#12solution: the participant forgot to update the date to the next day, since the timestamp is after midnight
correct_date_218 <- as.POSIXct("2023-10-22 02:15:00", format = "%Y-%m-%d %H:%M:%S", tz = tz)
wearlog_intervals_p <- wearlog_intervals_o %>%
  mutate(
    Datetime = if_else(Id == "218" & Datetime == "2023-10-21 02:15:00" & State == 2, correct_date_218, Datetime )
  )

#13Error: Consecutive values at record_id: 218 datetime: 2023-10-22 11:00:00 state: 1 
#13solution: this has now been solved with the solution above (#12solution)

#14Error: Consecutive values at record_id: 218 datetime: 2023-10-23 08:22:00 state: 1 
#14solution: this is the last day of participation for this individual. We will only keep the first entry anyways, so we can eliminate thi second entry which we would not use anyways (and is rdudant) - without caring about what the participant actually wanted to log

wearlog_intervals_q <- wearlog_intervals_p %>%
  filter(!(Id == "218" & Datetime == "2023-10-23 08:22:00" & State == 1))

```

#Quality check 2c: checking that our data cleaning worked 
```{r}
error_messages_states <- character(0) # We create an empty vector where we can store the errors

# Group by ID and then apply the quality check within each group
wearlog_intervals_q %>%
  group_by(Id) %>%
  arrange(Datetime) %>%  # Ensure data is sorted by Datetime
  mutate(PrevState = lag(State)) %>%
  filter(State == PrevState) %>%
  ungroup() %>%
  rowwise() %>%
  mutate(error_message = paste("Consecutive values at record_id:", Id, "datetime:", Datetime, "state:", State)) %>%
  pull(error_message) -> error_messages_states

# Check if there are error messages
if (length(error_messages_states) > 0) {
  # There are errors; print the error messages
  for (error_message in error_messages_states) {
    cat("Error:", error_message, "\n")
  }
} else {
  cat("No consecutive value errors found.")
}

#Looks like it did!
```
###Now that we have manually cleaned the data 


%>%
   mutate(
      State = case_when(
      State == 1 & (lag(State) == 0 | lag(State) == 2) ~ "on", #if on and previous one was off or sleep, it's on 
      State == 0 & (lead(State) == 2 | lag(State) == 1) ~ "off", #if off and next one is sleep, or previous one is on, it's off
      State == 2 & lead(State) == 1 ~ "sleep", #if sleep and next one is on, then it's sleep,
      .default = NA_character_)) #find way here to already detect the files where the last timestamp is not an on one 
    #recoding and filtering according to our criteria


to_remove <- as.POSIXct(c("2023-08-21 07:31:00", 
                          "2023-08-21 07:23:00", 
                          "2023-08-21 08:59:00",
                          "2023-09-04 07:28:00",
                          "2023-09-04 07:38:00",
                          "2023-09-04 08:10:00",
                          "2023-09-04 08:08:00",
                          "2023-09-11 07:30:00",
                          "2023-09-11 08:03:00",
                          "2023-09-11 07:45:00",
                          "2023-09-18 06:01:00",
                          "2023-09-18 08:03:00",
                          "2023-10-02 09:02:00",
                          "2023-10-09 08:27:00",
                          "2023-10-09 11:01:00",
                          "2023-10-23 08:13:00",
                          "2023-10-23 08:22:00",
                          "2023-10-30 07:58:00",
                          "2023-10-30 08:18:00",
                          "2023-11-06 08:00:00",
                          "2023-11-06 08:23:00",
                          "2023-11-06 06:49:00",
                          "2023-11-06 06:59:00",
                          "2023-11-06 07:07:00",
                          "2023-11-13 07:49:00",
                          "2023-11-13 07:09:00",
                          "2023-11-13 07:20:00",
                          "2023-11-13 07:55:00",
                          "2023-11-13 09:02:00",
                          "2023-11-13 08:15:00",
                          "2023-11-13 09:49:00"), tz = tz)


rows_to_remove <- wearlog_intervals$Datetime %in% to_remove

wearlog_intervals <- wearlog_intervals[!rows_to_remove, ]


wearlog_intervals <- wearlog_intervals %>%
  group_by(Id) %>%
  mutate(start_day = as.Date(first(Datetime)),
         exp_day = as.integer(difftime(Datetime, start_day, units = "days")) + 1) %>%
  ungroup()

last_day <- wearlog_intervals %>%
  group_by(Id) %>%
  filter(exp_day == 8) %>%
  mutate(on_check = (ifelse(State == "1" | State == "0", "on", "other"))) 
  
wearlog_intervals_f <- wearlog_intervals %>%
  right_join(last_day, by = c("Id", "exp_day"))
  
  
  
  


```

```{r}
#These are the 32 errors we get:
#Error: Consecutive values at record_id: 201 datetime: 2023-08-18 19:54:00 - This is ON
#Error: Consecutive values at record_id: 201 datetime: 2023-08-18 20:14:00 - This should be OFF


#Error: Consecutive values at record_id: 202 datetime: 2023-08-14 13:26:00 - Due to prev participant
#Error: Consecutive values at record_id: 202 datetime: 2023-08-15 07:24:00 
#Error: Consecutive values at record_id: 202 datetime: 2023-08-18 22:29:00 
#Error: Consecutive values at record_id: 205 datetime: 2023-08-28 15:42:00 
#Error: Consecutive values at record_id: 205 datetime: 2023-08-28 15:42:00 
#Error: Consecutive values at record_id: 205 datetime: 2023-09-02 16:47:00 
#Error: Consecutive values at record_id: 205 datetime: 2023-09-02 17:10:00 
#Error: Consecutive values at record_id: 205 datetime: 2023-09-03 09:40:00 
#Error: Consecutive values at record_id: 206 datetime: 2023-08-28 14:16:00 
#Error: Consecutive values at record_id: 208 datetime: 2023-09-04 12:36:00 
#Error: Consecutive values at record_id: 208 datetime: 2023-09-08 07:33:00 
#Error: Consecutive values at record_id: 209 datetime: 2023-09-08 00:58:00 
#Error: Consecutive values at record_id: 210 datetime: 2023-09-04 15:20:00 
#Error: Consecutive values at record_id: 215 datetime: 2023-10-02 11:30:00 
#Error: Consecutive values at record_id: 215 datetime: 2023-10-03 08:33:00 
#Error: Consecutive values at record_id: 215 datetime: 2023-10-07 01:15:00 
#Error: Consecutive values at record_id: 215 datetime: 2023-10-07 16:50:00 
#Error: Consecutive values at record_id: 216 datetime: 2023-10-02 14:31:00 
#Error: Consecutive values at record_id: 218 datetime: 2023-10-16 11:18:00 
#Error: Consecutive values at record_id: 218 datetime: 2023-10-21 02:15:00 
#Error: Consecutive values at record_id: 218 datetime: 2023-10-22 11:00:00 
#Error: Consecutive values at record_id: 218 datetime: 2023-10-23 08:22:00 
#Error: Consecutive values at record_id: 219 datetime: 2023-10-16 12:40:00 
#Error: Consecutive values at record_id: 222 datetime: 2023-10-23 13:10:00 
#Error: Consecutive values at record_id: 223 datetime: 2023-10-30 11:34:00 
#Error: Consecutive values at record_id: 224 datetime: 2023-10-30 13:24:00 
#Error: Consecutive values at record_id: 225 datetime: 2023-10-30 15:05:00 
#Error: Consecutive values at record_id: 226 datetime: 2023-10-30 16:34:00 
#Error: Consecutive values at record_id: 228 datetime: 2023-11-06 11:02:00 
#Error: Consecutive values at record_id: 229 datetime: 2023-11-06 12:34:00 
```

### Quality checks
We get an error message when using the import_Statechanges() function: "Warnung: There are consecutive states that are the same. This may or may not be an error in the data." Consecutive timestamps would have defaulted in NAs, as specified by the case_when() function above. Also, the first and last timestamp will be NA values, because of how we coded the states with case_when()
Let's check if this is the case by checking whcih Datetime ended up as NA. We would expect 26x2 = 52 entries.

```{r}
#We get all of the NA values
na_values <- wearlog_intervals %>%
  filter(is.na(State))

#We check whether the NA values are just the first and last timestamps
na_classification <- na_values %>%
  group_by(Id) %>%
  mutate(first = ifelse(row_number() == first(row_number()), "first", State),
         last = ifelse(row_number() == last(row_number()), "last", State))
```


```{r pressure, echo=FALSE}
#The first timestamp for every participant should be NA currently
first_tmp <- wearlog_intervals %>%
  group_by(Id) %>%
  filter(row_number() == first(row_number())) %>%
  ungroup()

#That's correct, and we want to change that to an "on" State
wearlog_int_on <- wearlog_intervals %>%
  group_by(Id) %>%
  mutate(State = ifelse(row_number() == first(row_number()), "on", State)) %>%
  ungroup()

#The last timestamp should also be NA for each participant
last_tmp <- wearlog_int_on %>%
  group_by(Id) %>%
  filter(row_number() == last(row_number())) %>%
  ungroup()

#Correct, and we want to change that to on
wearlog_int_clean <- wearlog_int_on %>%
  group_by(Id)%>%
  mutate(State = ifelse(row_number() == last(row_number()), "sleep", State)) %>%
  ungroup()


```



### Incorporate information about the black bag use (2nd source of non-wear)
We need to re-adjust the original Wear log file, where the black bag information is contained.
```{r pressure, echo=FALSE}
#First, turn it into a dataframe
wearlog_df <- lapply(
  wearlogfiles, 
  function(x) read.csv(x, stringsAsFactors = FALSE, sep = ";")
  ) %>% 
  list_c()

#Filter the columns of interest
wearlog_bag <- wearlog_df %>%
  select("record_id", "wearlog_off", "wearlog_past_off", "wearlog_bag", "wearlog_past_bag")

#This leads to a lot of NA values in the dataframe: when wearlog_bag has value, wearlog_past_bag is NA and viceversa. We want to delete rows where these values are both NA, as they are not useful for us right now. 
wearlog_bag_clean <- wearlog_bag %>%
    rowwise()%>%
    filter(xor(!is.na(wearlog_bag), !is.na(wearlog_past_bag)))


#Combine the information from the retrospectively logged events and events logged "in real time"
wearlog_bag_clean <- wearlog_bag_clean %>%
                    mutate(timestamp_combined = case_match(wearlog_off,
                                                           NA ~ wearlog_past_off, #if wearlog_off is NA, wearlog_past_off is taken
                                                           "" ~ wearlog_past_off, #if wearlog_off is empty, wearlog_past_off is taken
                                                           .default = wearlog_off),
                           bag_combined = case_match(wearlog_bag,
                                                     NA ~ wearlog_past_bag, #if wearlog_bag is NA, wearlog_past_bag is taken
                                                     .default = wearlog_bag))%>%
                    select(record_id, timestamp_combined, bag_combined) #select columns of interest

```


### Now we have a dataframe wearlog_bag_clean that contains timestamps for when the black bag was used or not used. We'd like to join this with the dataframe that contains the Wear log entries, i.e. wearlog_int_clean
```{r pressure, echo=FALSE}

##First, we need to do some renaming 
bag_df <- wearlog_bag_clean %>%
  rename(Id = record_id, Datetime = timestamp_combined, bag = bag_combined) %>%
  mutate(Id = as.factor(Id),
         Datetime = dmy_hm(Datetime, tz = "Europe/Berlin"))
  

#Now, we want to use left_join to merge the two dataframes 
joined_df <- left_join(wearlog_int_clean, bag_df, by = c("Datetime", "Id")) %>%
    mutate(bag = ifelse(is.na(bag), 2, bag)) #all the "on" and "sleep" intervals have bag = NA (since no bag was used here), so we give it a value of 2 

#Using the sc2interval function, we can turn the Datetime column of joined_df into an interval of time
joined_int <- joined_df %>%
  group_by(Id) %>% #need to do this to prevent that Datetime from 2 different participants get merged into the same interval
  LightLogR::sc2interval(full = TRUE, length.restriction = 7 * (60*60*24)) %>%
  ungroup()

#NOTE: By setting full sc2interval(full = TRUE) we ensure that the last interval for each participant end on Sunday at 00:00, which is the last day. But there is also now a new NA interval for the first participation day, up until when participants come in the lab. This will be ignored when using interval2state in the next lines

  
#Now that the joined_df is ready, we are ready to merge it to the light logger dataset
dataset.LL.joined <- dataset.LL.all %>% 
  interval2state(joined_int) #note that only the State (not bag) will be carried over from the original dataset

#Now we can apply interval2state a second time to integrate the bag information 
dataset.LL.clean <- dataset.LL.joined %>%
  interval2state(joined_int, State.colname = bag)



```

### Quality checks
Because of the work-around in the code chunk above, I would like to double check that the coding of State and bag was integrated correctly
```{r}
perform_quality_checks <- function(df) {
  for (i in 1:nrow(df)) {
    if (df$State[i] == 'on' || df$State[i] == 'sleep') {
      if (df$bag[i] != 2) {
        stop(paste("Quality check failed at index", i, ": State is", df$State[i], "but bag is not 2"))
      }
    } else if (df$State[i] == 'off') {
      if (df$bag[i] != 0 && df$bag[i] != 1) {
        stop(paste("Quality check failed at index", i, ": State is off but bag is neither 0 nor 1"))
      }
    } else {
      stop(paste("Invalid State value '", df$State[i], "' at index", i, ". State should be either 'on', 'off', or 'sleep'"))
    }
  }
}

tryCatch({
  perform_quality_checks(dataset.LL.clean)
  print("Quality checks passed successfully")
}, error = function(e) {
  print(e)
})

```

### Plot the non-wear time according to the wear log
```{r}
Sys.setlocale("LC_TIME", "en_US.UTF-8") #needed to run this code to have the days displayed in English and not German

#Non-wear time can be calculated from the joined_int dataset
off_states <- joined_int %>%
#filter for intervals on non-wear (State == "off")
  filter(State == "off") %>% 
  #calculate the non-wear time through the interval column
  mutate(off_time = int_length(Interval) %>% as_hms()) %>% 
  #group by date and summarize daily non-wear time
  mutate(Date = as.Date(int_end(Interval)), #first, Date and corresponding weekday are calculated
         day = format(Date, format = "%A", locale="English") %>% 
           forcats::fct_inorder()) %>%
  group_by(Id, day, .add = TRUE) %>%
  summarize(off_time = sum(off_time)) %>%
  ungroup()

#There are participants who have 0 non-wear time for a day, i.e. they have no State == off, who we still want to display as 0 points in our plot. Since we filtered for State == off above, we need to use complete to fill in days of 0 non-wear with 0 values. 
off_states <- off_states %>%
  complete(Id, day, fill = list(off_time = as_hms(0)))

off_states$off_time <- as.numeric(off_states$off_time, "hours")

```


```{r}
#plotting the data
nonwear_duration <- off_states %>% 
ggplot(aes(x = day, y = off_time)) +
  geom_violin(alpha = 0.3, aes(fill=day), trim = TRUE) + 
  geom_dotplot(binaxis = "y",
               stackdir = "center",
               dotsize = 0.5,
               binwidth = 0.1) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5, size = 26, face = "plain"),
        axis.text = element_text(size=18),
        axis.title = element_text(size=18),
        axis.title.y = element_text(size = 20),
        axis.title.x = element_text(size = 20),
        legend.position = "none") +
  xlab("Experimental day") + 
  ylab("Non-wear time (hours)") +
  scale_y_continuous(breaks = c(0, 2, 4, 6, 8, 10, 12, 14, 16), 
                     label = c(0, 2, 4, 6, 8, 10, 12, 14, 16), 
                     expand = c(0,0)) +
  ggtitle("Self-reported non-wear time entries (Wear log)")
```

###Saving  
```{r}
ggsave(filename = "nonwear_all.png",
       plot = nonwear_duration,
       width = 13,
       height = 14,
       dpi = 600,
       path= "F:/cyepi/code/outputs")

ggsave(filename = "nonwear_all.pdf",
       plot = nonwear_duration,
       width = 13,
       height = 14,
       dpi = 600,
       path= "F:/cyepi/code/outputs")
```

###While the plot above gives us an overview of the non-wear time for all participants, we would like to plot this as an histogram of non-wear time distribution, ranging from 0 non wear time to 100% non wear time

```{r}
#First, while all participants took part in the experiment for 7 days, they started at different times, and so it is important not just to approximate to 7 days (168 hours), but to calculate the specific 100% of "participation time" for each participant. For this, we first need to calculate the n of hours that each participant spends in the experiment.

particip_int <- filtered_time %>%
  mutate(par_int = lubridate::interval(start, end),
         length_par = lubridate::int_length(par_int) %>% as_hms()) %>% #tot hours of participation for each participant
  select(Id, length_par)

```

###Visualise how much time participants spend in which State (on/off/sleep)
```{r}
library(ggdist)

#Time in each interval can be calculated from joined_int 
int_types <- joined_int %>%
  #calculate length of each interval
  mutate(int_length = int_length(Interval) %>% as_hms()) %>% 
  #group by date and summarize 
  mutate(Date = as.Date(int_end(Interval)), #first, Date and corresponding weekday are calculated
         day = format(Date, format = "%A", locale="English") %>% 
           forcats::fct_inorder()) %>%
  group_by(Id, State, .add = TRUE) %>%
  summarize(tot_intlength = sum(int_length) %>% as_hms()) %>%
  ungroup() %>%
  filter(!is.na(State))

# Normalise it to the total time they participated in the experiment
int_types <- int_types %>%
  left_join(particip_int, by ="Id") %>% #append the column containing total participation hours from the particip_int df
  mutate(per_length = (as.numeric(tot_intlength)/as.numeric(length_par))*100) #convert to numeric as division betwen difftime objects is not supported


#Calculating median time in each state

summary <- int_types %>%
  group_by(State) %>%
  summarise(mean = mean(per_length),
            sd = sd(per_length),
            min = min(per_length),
            max = max(per_length),
            median = median(per_length),
            range = max-min) %>%
  ungroup()

as.factor(int_types$State)

#Plot
int_types$State <- factor(int_types$State, levels = unique(int_types$State)[order(int_types$per_length, decreasing = TRUE)])

states_dist_jitter <- ggplot(data = int_types, aes(x=per_length, y = State, fill = State)) +
  xlim(NA,100) +
  ggdist::stat_halfeye(
    aes(colour = State,
        fill = State),
    adjust = .5,
    justification = -.25,
    point_color = NA,
    interval_color = NA
    ) +
  geom_boxplot(
    aes(color = State),
    width = .2,
    alpha = .2,
    outlier.shape = NA
  ) +
  geom_jitter(
    aes(colour = State),
    fill = "white",
    height = .1,
    alpha = .3
  ) +
  scale_fill_manual(
    values = c("off" = "#16439C", "on" = "palegreen4", "sleep" = "darkgoldenrod2")) +
  scale_color_manual(
    values = c("off" = "#16439C", "on" = "palegreen4", "sleep" = "darkgoldenrod2")) +
  scale_y_discrete(labels = c("on" = "On", "off" = "Off", "sleep" = "Off while\nsleeping")) +
  theme_classic() +
  ggpubr::rremove("ylab") +
  ggpubr::rremove("y.ticks") +
  labs(title = "(Non-)wear time distribution across the week", x = "Percentage of time (%)") +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5, size = 24),
        axis.text.x = element_text(size = 16),
        axis.title = element_text(size = 18),
        axis.text.y = element_text(size = 16))

#Same plot without jitter and boxplot, just with distribution
  states_dist_histo <- ggplot(data = int_types, aes(x=per_length, y = State, fill = State)) +
  xlim(NA,100) +
  ggdist::stat_halfeye(
    aes(colour = State,
        fill = State),
    adjust = .5,
    point_color = NA,
    interval_color = NA
 #   .width = .7
    ) +
  ggdist::stat_dotsinterval(
    side = "bottom",
    scale = .3,
    slab_colour = NA,
    slab_linewidth = NA) +
  scale_fill_manual(
    values = c("off" = "#16439C", "on" = "palegreen4", "sleep" = "darkgoldenrod2")) +
  scale_y_discrete(labels = c("on" = "On", "off" = "Off", "sleep" = "Off while\nsleeping")) +
  theme_classic() +
  ggpubr::rremove("ylab") +
  ggpubr::rremove("y.ticks") +
  labs(title = "(Non-)wear time distribution across the week", x = "Percentage of time (%)") +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5, size = 24),
        axis.text.x = element_text(size = 16),
        axis.title = element_text(size = 18),
        axis.text.y = element_text(size = 16))


```

###Save plot above
```{r}
ggsave(filename = "state_dist_jitter.png",
       plot = states_dist_jitter ,
       width = 8,
       height = 5,
       dpi = 600,
       path= "F:/cyepi/code/outputs")
```

##Perform a sanity check that plot sleep and wake time from sleep diary 
In the plot above, we visualised time spent in each of the non-wear states: off (device not worn), on (device worn) and off for sleep (device not worn during sleep). As a sanity check, the time that the device is not worn during sleep should be similar to the time that the participants reported actually sleeping, as indicated by the sleep diary. For this reason, we follow a similar approach to the code above to visualise the amount of time participants spend asleep or awake according to the sleep diary. 
```{r}
#Locate the sleep diary files
path_sleep <- here("F:/cyepi/data/raw/group/sleepdiary")

# Get the files names from directory
sleepdiary = list.files(path_sleep, pattern="*.csv", full.names = TRUE)

#Using LightLogR, we import the files and label each timestamp as wake or sleep
sleepdiary_df <- LightLogR::import_Statechanges(sleepdiary,
                                     Datetime.format = "dmyHM",
                                     State.colnames = c("sleep", "offset"),
                                     State.encoding = c("sleep", "wake"),
                                     Id.colname = record_id,
                                     sep = ";",
                                     dec = ",",
                                     tz = tz)

#Similar to what was done for the wearlog intervals, we now turn the state changes of the sleep diary to an interval
sleep_int <- sleepdiary_df %>%
  sc2interval() %>%
  filter(!is.na(State))

#Calculate the amount of time spent in each state (either awake or alseep), for each participant across the whole experiment duration
sleep_int <- sleep_int %>%
#calculate length of each interval
  mutate(int_length = int_length(Interval) %>% as_hms()) %>% 
  #group by date and summarize 
  mutate(Date = as.Date(int_end(Interval)), #first, Date and corresponding weekday are calculated
         day = format(Date, format = "%A", locale="English") %>% 
           forcats::fct_inorder()) %>%
  group_by(Id, State, .add = TRUE) %>%
  summarize(tot_intlength = sum(int_length) %>% as_hms()) %>%
  ungroup() %>%
  filter(!is.na(State))


# Normalise it to the total time they participated in the experiment
sleep_int <- sleep_int %>%
  left_join(particip_int, by ="Id") %>% #append the column containing total participation hours from the particip_int df
  #note that particip_int has been calculate earlier and can be reused here 
  mutate(per_length = (as.numeric(tot_intlength)/as.numeric(length_par))*100) #convert to numeric as division betwen difftime objects is not supported

#Turn state into factor
as.factor(sleep_int$State)

#Organise the order of the factor levels to determine what comes first in the plot
sleep_int$State <- factor(sleep_int$State, levels = unique(sleep_int$State)[order(sleep_int$per_length, decreasing = TRUE)])

#Plot
sleep_wake_dist <-
  ggplot(data = sleep_int, aes(x=per_length, y = State, fill = State)) +
  xlim(NA,100) +
  ggdist::stat_halfeye(
    aes(colour = State,
        fill = State),
    adjust = .5,
    justification = -.15,
    point_color = NA,
    interval_color = NA
    ) +
  geom_boxplot(
    aes(color = State),
    width = .2,
    alpha = .2,
    outlier.shape = NA
  ) +
  geom_jitter(
    aes(colour = State),
    fill = "white",
    height = .1,
    alpha = .3
  ) +
  scale_fill_manual(
    values = c("sleep" = "darkgoldenrod2", "wake" = "darkcyan")) +
  scale_color_manual(
    values = c("sleep" = "darkgoldenrod2", "wake" = "darkcyan")) +
  scale_y_discrete(labels = c("sleep" = "Sleep", "wake" = "Wake")) +
  theme_classic() +
  ggpubr::rremove("ylab") +
  ggpubr::rremove("y.ticks") +
  labs(title = "Sleep and wake distribution across the week", x = "Percentage of time (%)") +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5, size = 24),
        axis.text.x = element_text(size = 16),
        axis.title = element_text(size = 18),
        axis.text.y = element_text(size = 16))

##Save plot above
ggsave(filename = "sleep_wake_dist.png",
       plot = sleep_wake_dist ,
       width = 8,
       height = 5,
       dpi = 600,
       path= "F:/cyepi/code/outputs")
```

#Do the same but no distinction between weekday and weekend
```{r}
tot_nonwear <- int_types%>%
  filter(State == "off")

#tot_nonwear$offtime_per <- (tot_nonwear$off_time / (24*7))*100

nonwear_dist_overview <- ggplot(data = tot_nonwear, aes(x = per_length, fill = State))  +
  xlim(NA, 100) +
  ggdist::stat_halfeye(
    aes(colour = State,
        fill = State),
    adjust = .5,
    ) +
  ggdist::stat_dotsinterval(
    side = "bottom",
    scale = .3,
    slab_colour = NA,
    slab_linewidth = NA) +
   scale_fill_manual(values = c("off" = "#16439C")) +
  theme_classic() +
  labs(title = "Non-wear time distribution", x = "Non-wear time (%)") +
  ggpubr::rremove("ylab") +
  ggpubr::rremove("y.ticks") +
  ggpubr::rremove("y.text") +
  theme(plot.title = element_text(hjust = 0.5, size = 24),
        axis.text.x = element_text(size = 16),
        axis.title = element_text(size = 18),
        axis.text.x.top = element_blank(),
        axis.ticks.x.top = element_blank(),
        axis.line.x.top = element_blank(),
        legend.position = "none") +
  scale_x_break(c(15,99.9),
                ticklabels = 100)

ggsave(filename = "nonwear_dist_overview_100.png",
       plot = nonwear_dist_overview ,
       width = 8,
       height = 5,
       dpi = 600,
       path= "F:/cyepi/code/outputs")
```




