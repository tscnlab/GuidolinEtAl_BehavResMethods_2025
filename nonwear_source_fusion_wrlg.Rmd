---
title: "nonwear_source_fusion"
author: "Carolina Guidolin"
date: "2023-11-21"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Backgorund
The aim is to describe and compare strategies for tracking non-wear time of wearable light loggers used in ambulatory light exposure studies. This can help other researchers to plan their experiments and choose a non-wear time strategy which fits their research requirements. 

##Dataset description
Participants N = 26
Duration: 7 full days
Wearable device: ActLumus with 10 seconds sampling period, worn on spectacles ("light glasses")

Non-wear time information is given by three sources:  
1. Wear log completed by the participant with following information: 
  - Timestamp of taking the light glasses off (current/retrospective) 
  - Timestamp of placing the light glasses back on (current/retrospective) 
  - Timestamp of taking the light glasses off before bed (current/retrospective) 
  - Use of black bag during non-wear episode (current/retrospective) 

2. Button presses done by the participant (logged by ActLumus); 

3. Light while in black bag (mEDI ≤1 lux during non-wear time) 
  - Note: this is partly related to the Wear log, as information on whether the black bag was used or not is contained in the Wear log 

Each of these three sources can be used individually to detect a non-wear period. However, the Wear log entries were monitored twice a day by the experimenter, and thus considered as the “ground truth” for non-wear detection. 

## Research question
The ovearching RQ is: What is the concordance between different sources of non-wear?

##Data fusion 
To answer the RQ, we first need to integrate the data coming from these three sources. We will do this in a LightLogR native format, as in the future we might want to have these functions built in LightLogR.

###Load in the necessary packages
```{r}
library(tidyverse)
library(hms)
library(here)
library(scales)
library(lubridate)
library(LightLogR)
library(ggpubr)
library(ggbreak)
```


### Loading actlumus data 
First, we need to import the ActLumus file where the button press information is contained. We will need this later.
```{r}
Sys.setlocale("LC_TIME", "en_US.UTF-8") #needed to run this code to have the days displayed in English and not German

path <- "G:/cyepi/code/pre-processing/nonwear_detection/actlumus"
tz <- "Europe/Berlin"

# Get a list of file paths in the specified directory
actlumusfiles <- list.files(path, pattern = ".txt", full.names = TRUE)

# Create an empty dataframe to store the combined data
dataset.LL.all <- data.frame()

# Iterate over each file and import data
# Ensure that the datasets crossing from DST to ST on 29.10.2023 are adjusted for using dst_adjustment function 
dataset.LL.all <- import$ActLumus(actlumusfiles, tz = tz, auto.id = "^(\\d{3})", dst_adjustment = TRUE)

```

Every participant started at different times. We will have to specify start and end time manually. 
Start times are taken as the first timestamp when the participant started the study. This is reported in the Wear log.
End times are taken as the timestamp of "putting the light glasses back on" on the morning of the last day of the experiment, i.e. when participants had to return to the laboratory. In case this was missing, "data"out of bed" data from the sleep diary was used (this was the case for 4 participants), as this would be the closest approximation. For one participant (213), the data from the sleep diary was missing as well. Thus, the end time was determined as midnight of the last experimental day (Sunday).

```{r}
filtered_time <- data.frame(
  Id = c("201", "202", "204", "205", "206", "208", "209", "210", "212", "213", "214", "215", "216", "218", "219", "221", "222", "223", "224", "225", "226", "227", "228", "229", "230", "231"),
  start = as.POSIXct(c("2023-08-14 12:40:00", "2023-08-14 13:26:00", "2023-08-14 14:43:00", "2023-08-28 15:42:00", "2023-08-28 14:16:00", "2023-09-04 12:36:00", "2023-09-04 14:01:00", "2023-09-04 15:20:00", "2023-09-11 13:03:00", "2023-09-11 15:06:00", "2023-09-25 14:56:00", "2023-10-02 11:30:00", "2023-10-02 14:31:00", "2023-10-16 11:18:00", "2023-10-16 12:40:00", "2023-10-23 11:22:00", "2023-10-23 13:10:00", "2023-10-30 11:34:00", "2023-10-30 13:24:00", "2023-10-30 15:05:00", "2023-10-30 16:34:00", "2023-10-30 17:44:00", "2023-11-06 11:02", "2023-11-06 12:34", "2023-11-06 14:02", "2023-11-06 17:12" )),    # Add start times
  end = as.POSIXct(c("2023-08-20 23:59:59", "2023-08-20 23:59:59", "2023-08-20 23:59:59", "2023-09-03 23:59:59", "2023-09-03 23:59:59", "2023-09-10 23:59:59", "2023-09-10 23:59:59", "2023-09-10 23:59:59", "2023-09-17 23:59:59", "2023-09-17 23:59:59", "2023-10-01 23:59:59", "2023-10-08 23:59:59", "2023-10-08 23:59:59", "2023-10-22 23:59:59" , "2023-10-22 23:59:59", "2023-10-29 23:59:59", "2023-10-29 23:59:59", "2023-11-05 23:59:59", "2023-11-05 23:59:59", "2023-11-05 23:59:59", "2023-11-05 23:59:59", "2023-11-05 23:59:59", "2023-11-12 23:59:59", "2023-11-12 23:59:59", "2023-11-12 23:59:59", "2023-11-12 23:59:59"))            # Add end times
)
```


```{r}
filtered_time <- data.frame(
  Id = c("201", "202", "204", "205", "206", "208", "209", "210", "212", "213", "214", "215", "216", "218", "219", "221", "222", "223", "224", "225", "226", "227", "228", "229", "230", "231"),
  start = as.POSIXct(c("2023-08-14 12:40:00", #201
                       "2023-08-14 13:26:00", #202
                       "2023-08-14 14:43:00", #204
                       "2023-08-28 15:42:00", #205
                       "2023-08-28 14:16:00", #206
                       "2023-09-04 12:36:00", #208
                       "2023-09-04 14:01:00", #209
                       "2023-09-04 15:20:00", #210
                       "2023-09-11 13:03:00", #212
                       "2023-09-11 15:06:00", #213
                       "2023-09-25 14:56:00", #214
                       "2023-10-02 11:30:00", #215
                       "2023-10-02 14:31:00", #216
                       "2023-10-16 11:18:00", #218
                       "2023-10-16 12:40:00", #219
                       "2023-10-23 11:22:00", #221
                       "2023-10-23 13:10:00", #222
                       "2023-10-30 11:34:00", #223
                       "2023-10-30 13:24:00", #224
                       "2023-10-30 15:05:00", #225
                       "2023-10-30 16:34:00", #226
                       "2023-10-30 17:44:00", #227
                       "2023-11-06 11:02:00", #228
                       "2023-11-06 12:34:00", #229
                       "2023-11-06 14:02:00", #230
                       "2023-11-06 17:12:00"  #231
                       )),    # Add start times
  end = as.POSIXct(c("2023-08-21 07:31:00", #201
                     "2023-08-21 07:23:00", #202
                     "2023-08-21 08:59:00", #204
                     "2023-09-04 07:28:00", #205
                     "2023-09-04 08:08:00", #206
                     "2023-09-11 07:30:00", #208
                     "2023-09-11 07:45:00", #209
                     "2023-09-11 06:16:00", #210 from sleep diary, out_ofbed
                     "2023-09-18 06:01:00", #212 
                     "2023-09-17 23:59:59", #213 leaving it as is because of missing data
                     "2023-10-02 09:02:00", #214
                     "2023-10-09 08:27:00", #215
                     "2023-10-09 11:01:00", #216
                     "2023-10-23 08:13:00", #218
                     "2023-10-23 07:10:00", #219 from sleep diary, out_ofbed
                     "2023-10-30 07:58:00", #221
                     "2023-10-30 08:18:00", #222
                     "2023-11-06 08:00:00", #223
                     "2023-11-06 08:23:00", #224
                     "2023-11-06 05:44:00", #225 from sleep diary, out_ofbed
                     "2023-11-06 06:49:00", #226
                     "2023-11-06 07:07:00", #227
                     "2023-11-13 07:49:00", #228
                     "2023-11-13 07:09:00", #229
                     "2023-11-13 08:02:00", #230 from sleep diary, out_ofbed
                     "2023-11-13 08:15:00" #231
                     ))# Add end times
)

dataset.LL.all <- dataset.LL.all %>%
  inner_join(filtered_time, by = "Id") %>%
  filter(Datetime >= start, Datetime <= end) %>%
  select(-start, -end)

```

### Loading Wear log files 

First, we need to import the data from the wear log
```{r}
filepath <- here("G:/cyepi/code/pre-processing/nonwear_detection/wearlog")

# Get the files names from directory
wearlogfiles = list.files(filepath, pattern="*.csv", full.names = TRUE)

```

### Non-wear time according to the Wear log (1st source of non-wear)
Here we create States (using import_Statechanges) that code for the 3 most important information contained in the Wear log: 1. When the light glasses were on, 2. When the light glasses were off, 3. When the light glasses were put off for sleep. Retrspective and real-time information are treated as equal for this step. 
```{r pressure, echo=FALSE}
wearlog_intervals <- 
  #filenames:
  wearlogfiles %>% 
  #import_Statechanges from LightLogR to create states based on timestamps
  LightLogR::import_Statechanges(
    sep = ";", dec = ",", Datetime.format = "dmyHM", tz = "Europe/Berlin", 
    Id.colname = record_id,
    State.colnames = 
      c("wearlog_on", "wearlog_off", "wearlog_past_on", "wearlog_past_off", "wearlog_bed", "wearlog_past_sleep"),
    State.encoding = 
      c("1", "0", "1", "0", "2", "2") #off coded as 0, on coded as 1, sleep coded as 2
    ) 

#Quality check: find identical consecutive events

error_messages <- character(0) # We create an empty vector where we can store the errors

for (i in 2:(nrow(wearlog_intervals) - 1)) {
  if (wearlog_intervals$State[i] == wearlog_intervals$State[i - 1]) { # we check if the current row has the same value as the previous row
    # If that's the case, add an error message
    error_messages <- c(
      error_messages,
      paste("Consecutive values at record_id:", wearlog_intervals$Id[i],
            "datetime:", wearlog_intervals$Datetime[i])
    )
  }
}

# Check if there are error messages
if (length(error_messages) > 0) {
  # There are errors; print the error messages
  for (error_message in error_messages) {
    cat("Error:", error_message, "\n")
  }
} else {
  cat("No consecutive value errors found.")
}

#32 instances of error messages found
#201 - change 

%>%
   mutate(
      State = case_when(
      State == 1 & (lag(State) == 0 | lag(State) == 2) ~ "on", #if on and previous one was off or sleep, it's on 
      State == 0 & (lead(State) == 2 | lag(State) == 1) ~ "off", #if off and next one is sleep, or previous one is on, it's off
      State == 2 & lead(State) == 1 ~ "sleep", #if sleep and next one is on, then it's sleep,
      .default = NA_character_)) #find way here to already detect the files where the last timestamp is not an on one 
    #recoding and filtering according to our criteria


to_remove <- as.POSIXct(c("2023-08-21 07:31:00", 
                          "2023-08-21 07:23:00", 
                          "2023-08-21 08:59:00",
                          "2023-09-04 07:28:00",
                          "2023-09-04 07:38:00",
                          "2023-09-04 08:10:00",
                          "2023-09-04 08:08:00",
                          "2023-09-11 07:30:00",
                          "2023-09-11 08:03:00",
                          "2023-09-11 07:45:00",
                          "2023-09-18 06:01:00",
                          "2023-09-18 08:03:00",
                          "2023-10-02 09:02:00",
                          "2023-10-09 08:27:00",
                          "2023-10-09 11:01:00",
                          "2023-10-23 08:13:00",
                          "2023-10-23 08:22:00",
                          "2023-10-30 07:58:00",
                          "2023-10-30 08:18:00",
                          "2023-11-06 08:00:00",
                          "2023-11-06 08:23:00",
                          "2023-11-06 06:49:00",
                          "2023-11-06 06:59:00",
                          "2023-11-06 07:07:00",
                          "2023-11-13 07:49:00",
                          "2023-11-13 07:09:00",
                          "2023-11-13 07:20:00",
                          "2023-11-13 07:55:00",
                          "2023-11-13 09:02:00",
                          "2023-11-13 08:15:00",
                          "2023-11-13 09:49:00"), tz = tz)


rows_to_remove <- wearlog_intervals$Datetime %in% to_remove

wearlog_intervals <- wearlog_intervals[!rows_to_remove, ]


wearlog_intervals <- wearlog_intervals %>%
  group_by(Id) %>%
  mutate(start_day = as.Date(first(Datetime)),
         exp_day = as.integer(difftime(Datetime, start_day, units = "days")) + 1) %>%
  ungroup()

last_day <- wearlog_intervals %>%
  group_by(Id) %>%
  filter(exp_day == 8) %>%
  mutate(on_check = (ifelse(State == "1" | State == "0", "on", "other"))) 
  
wearlog_intervals_f <- wearlog_intervals %>%
  right_join(last_day, by = c("Id", "exp_day"))
  
  
  
  


```
These are the 32 errors we get:
Error: Consecutive values at record_id: 201 datetime: 2023-08-18 19:54:00 
Error: Consecutive values at record_id: 201 datetime: 2023-08-18 20:14:00 
Error: Consecutive values at record_id: 202 datetime: 2023-08-14 13:26:00 
Error: Consecutive values at record_id: 202 datetime: 2023-08-15 07:24:00 
Error: Consecutive values at record_id: 202 datetime: 2023-08-18 22:29:00 
Error: Consecutive values at record_id: 205 datetime: 2023-08-28 15:42:00 
Error: Consecutive values at record_id: 205 datetime: 2023-08-28 15:42:00 
Error: Consecutive values at record_id: 205 datetime: 2023-09-02 16:47:00 
Error: Consecutive values at record_id: 205 datetime: 2023-09-02 17:10:00 
Error: Consecutive values at record_id: 205 datetime: 2023-09-03 09:40:00 
Error: Consecutive values at record_id: 206 datetime: 2023-08-28 14:16:00 
Error: Consecutive values at record_id: 208 datetime: 2023-09-04 12:36:00 
Error: Consecutive values at record_id: 208 datetime: 2023-09-08 07:33:00 
Error: Consecutive values at record_id: 209 datetime: 2023-09-08 00:58:00 
Error: Consecutive values at record_id: 210 datetime: 2023-09-04 15:20:00 
Error: Consecutive values at record_id: 215 datetime: 2023-10-02 11:30:00 
Error: Consecutive values at record_id: 215 datetime: 2023-10-03 08:33:00 
Error: Consecutive values at record_id: 215 datetime: 2023-10-07 01:15:00 
Error: Consecutive values at record_id: 215 datetime: 2023-10-07 16:50:00 
Error: Consecutive values at record_id: 216 datetime: 2023-10-02 14:31:00 
Error: Consecutive values at record_id: 218 datetime: 2023-10-16 11:18:00 
Error: Consecutive values at record_id: 218 datetime: 2023-10-21 02:15:00 
Error: Consecutive values at record_id: 218 datetime: 2023-10-22 11:00:00 
Error: Consecutive values at record_id: 218 datetime: 2023-10-23 08:22:00 
Error: Consecutive values at record_id: 219 datetime: 2023-10-16 12:40:00 
Error: Consecutive values at record_id: 222 datetime: 2023-10-23 13:10:00 
Error: Consecutive values at record_id: 223 datetime: 2023-10-30 11:34:00 
Error: Consecutive values at record_id: 224 datetime: 2023-10-30 13:24:00 
Error: Consecutive values at record_id: 225 datetime: 2023-10-30 15:05:00 
Error: Consecutive values at record_id: 226 datetime: 2023-10-30 16:34:00 
Error: Consecutive values at record_id: 228 datetime: 2023-11-06 11:02:00 
Error: Consecutive values at record_id: 229 datetime: 2023-11-06 12:34:00 

### Quality checks
We get an error message when using the import_Statechanges() function: "Warnung: There are consecutive states that are the same. This may or may not be an error in the data." Consecutive timestamps would have defaulted in NAs, as specified by the case_when() function above. Also, the first and last timestamp will be NA values, because of how we coded the states with case_when()
Let's check if this is the case by checking whcih Datetime ended up as NA. We would expect 26x2 = 52 entries.

```{r}
#We get all of the NA values
na_values <- wearlog_intervals %>%
  filter(is.na(State))

#We check whether the NA values are just the first and last timestamps
na_classification <- na_values %>%
  group_by(Id) %>%
  mutate(first = ifelse(row_number() == first(row_number()), "first", State),
         last = ifelse(row_number() == last(row_number()), "last", State))
```


```{r pressure, echo=FALSE}
#The first timestamp for every participant should be NA currently
first_tmp <- wearlog_intervals %>%
  group_by(Id) %>%
  filter(row_number() == first(row_number())) %>%
  ungroup()

#That's correct, and we want to change that to an "on" State
wearlog_int_on <- wearlog_intervals %>%
  group_by(Id) %>%
  mutate(State = ifelse(row_number() == first(row_number()), "on", State)) %>%
  ungroup()

#The last timestamp should also be NA for each participant
last_tmp <- wearlog_int_on %>%
  group_by(Id) %>%
  filter(row_number() == last(row_number())) %>%
  ungroup()

#Correct, and we want to change that to on
wearlog_int_clean <- wearlog_int_on %>%
  group_by(Id)%>%
  mutate(State = ifelse(row_number() == last(row_number()), "sleep", State)) %>%
  ungroup()


```



### Incorporate information about the black bag use (2nd source of non-wear)
We need to re-adjust the original Wear log file, where the black bag information is contained.
```{r pressure, echo=FALSE}
#First, turn it into a dataframe
wearlog_df <- lapply(
  wearlogfiles, 
  function(x) read.csv(x, stringsAsFactors = FALSE, sep = ";")
  ) %>% 
  list_c()

#Filter the columns of interest
wearlog_bag <- wearlog_df %>%
  select("record_id", "wearlog_off", "wearlog_past_off", "wearlog_bag", "wearlog_past_bag")

#This leads to a lot of NA values in the dataframe: when wearlog_bag has value, wearlog_past_bag is NA and viceversa. We want to delete rows where these values are both NA, as they are not useful for us right now. 
wearlog_bag_clean <- wearlog_bag %>%
    rowwise()%>%
    filter(xor(!is.na(wearlog_bag), !is.na(wearlog_past_bag)))


#Combine the information from the retrospectively logged events and events logged "in real time"
wearlog_bag_clean <- wearlog_bag_clean %>%
                    mutate(timestamp_combined = case_match(wearlog_off,
                                                           NA ~ wearlog_past_off, #if wearlog_off is NA, wearlog_past_off is taken
                                                           "" ~ wearlog_past_off, #if wearlog_off is empty, wearlog_past_off is taken
                                                           .default = wearlog_off),
                           bag_combined = case_match(wearlog_bag,
                                                     NA ~ wearlog_past_bag, #if wearlog_bag is NA, wearlog_past_bag is taken
                                                     .default = wearlog_bag))%>%
                    select(record_id, timestamp_combined, bag_combined) #select columns of interest

```


### Now we have a dataframe wearlog_bag_clean that contains timestamps for when the black bag was used or not used. We'd like to join this with the dataframe that contains the Wear log entries, i.e. wearlog_int_clean
```{r pressure, echo=FALSE}

##First, we need to do some renaming 
bag_df <- wearlog_bag_clean %>%
  rename(Id = record_id, Datetime = timestamp_combined, bag = bag_combined) %>%
  mutate(Id = as.factor(Id),
         Datetime = dmy_hm(Datetime, tz = "Europe/Berlin"))
  

#Now, we want to use left_join to merge the two dataframes 
joined_df <- left_join(wearlog_int_clean, bag_df, by = c("Datetime", "Id")) %>%
    mutate(bag = ifelse(is.na(bag), 2, bag)) #all the "on" and "sleep" intervals have bag = NA (since no bag was used here), so we give it a value of 2 

#Using the sc2interval function, we can turn the Datetime column of joined_df into an interval of time
joined_int <- joined_df %>%
  group_by(Id) %>% #need to do this to prevent that Datetime from 2 different participants get merged into the same interval
  LightLogR::sc2interval(full = TRUE, length.restriction = 7 * (60*60*24)) %>%
  ungroup()

#NOTE: By setting full sc2interval(full = TRUE) we ensure that the last interval for each participant end on Sunday at 00:00, which is the last day. But there is also now a new NA interval for the first participation day, up until when participants come in the lab. This will be ignored when using interval2state in the next lines

  
#Now that the joined_df is ready, we are ready to merge it to the light logger dataset
dataset.LL.joined <- dataset.LL.all %>% 
  interval2state(joined_int) #note that only the State (not bag) will be carried over from the original dataset

#Now we can apply interval2state a second time to integrate the bag information 
dataset.LL.clean <- dataset.LL.joined %>%
  interval2state(joined_int, State.colname = bag)



```

### Quality checks
Because of the work-around in the code chunk above, I would like to double check that the coding of State and bag was integrated correctly
```{r}
perform_quality_checks <- function(df) {
  for (i in 1:nrow(df)) {
    if (df$State[i] == 'on' || df$State[i] == 'sleep') {
      if (df$bag[i] != 2) {
        stop(paste("Quality check failed at index", i, ": State is", df$State[i], "but bag is not 2"))
      }
    } else if (df$State[i] == 'off') {
      if (df$bag[i] != 0 && df$bag[i] != 1) {
        stop(paste("Quality check failed at index", i, ": State is off but bag is neither 0 nor 1"))
      }
    } else {
      stop(paste("Invalid State value '", df$State[i], "' at index", i, ". State should be either 'on', 'off', or 'sleep'"))
    }
  }
}

tryCatch({
  perform_quality_checks(dataset.LL.clean)
  print("Quality checks passed successfully")
}, error = function(e) {
  print(e)
})

```

### Plot the non-wear time according to the wear log
```{r}
Sys.setlocale("LC_TIME", "en_US.UTF-8") #needed to run this code to have the days displayed in English and not German

#Non-wear time can be calculated from the joined_int dataset
off_states <- joined_int %>%
#filter for intervals on non-wear (State == "off")
  filter(State == "off") %>% 
  #calculate the non-wear time through the interval column
  mutate(off_time = int_length(Interval) %>% as_hms()) %>% 
  #group by date and summarize daily non-wear time
  mutate(Date = as.Date(int_end(Interval)), #first, Date and corresponding weekday are calculated
         day = format(Date, format = "%A", locale="English") %>% 
           forcats::fct_inorder()) %>%
  group_by(Id, day, .add = TRUE) %>%
  summarize(off_time = sum(off_time)) %>%
  ungroup()

#There are participants who have 0 non-wear time for a day, i.e. they have no State == off, who we still want to display as 0 points in our plot. Since we filtered for State == off above, we need to use complete to fill in days of 0 non-wear with 0 values. 
off_states <- off_states %>%
  complete(Id, day, fill = list(off_time = as_hms(0)))

off_states$off_time <- as.numeric(off_states$off_time, "hours")

```


```{r}
#plotting the data
nonwear_duration <- off_states %>% 
ggplot(aes(x = day, y = off_time)) +
  geom_violin(alpha = 0.3, aes(fill=day), trim = TRUE) + 
  geom_dotplot(binaxis = "y",
               stackdir = "center",
               dotsize = 0.5,
               binwidth = 0.1) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5, size = 26, face = "plain"),
        axis.text = element_text(size=18),
        axis.title = element_text(size=18),
        axis.title.y = element_text(size = 20),
        axis.title.x = element_text(size = 20),
        legend.position = "none") +
  xlab("Experimental day") + 
  ylab("Non-wear time (hours)") +
  scale_y_continuous(breaks = c(0, 2, 4, 6, 8, 10, 12, 14, 16), 
                     label = c(0, 2, 4, 6, 8, 10, 12, 14, 16), 
                     expand = c(0,0)) +
  ggtitle("Self-reported non-wear time entries (Wear log)")
```

###Saving  
```{r}
ggsave(filename = "nonwear_all.png",
       plot = nonwear_duration,
       width = 13,
       height = 14,
       dpi = 600,
       path= "F:/cyepi/code/outputs")

ggsave(filename = "nonwear_all.pdf",
       plot = nonwear_duration,
       width = 13,
       height = 14,
       dpi = 600,
       path= "F:/cyepi/code/outputs")
```

###While the plot above gives us an overview of the non-wear time for all participants, we would like to plot this as an histogram of non-wear time distribution, ranging from 0 non wear time to 100% non wear time

```{r}
#First, while all participants took part in the experiment for 7 days, they started at different times, and so it is important not just to approximate to 7 days (168 hours), but to calculate the specific 100% of "participation time" for each participant. For this, we first need to calculate the n of hours that each participant spends in the experiment.

particip_int <- filtered_time %>%
  mutate(par_int = lubridate::interval(start, end),
         length_par = lubridate::int_length(par_int) %>% as_hms()) %>% #tot hours of participation for each participant
  select(Id, length_par)

```

###Visualise how much time participants spend in which State (on/off/sleep)
```{r}
library(ggdist)

#Time in each interval can be calculated from joined_int 
int_types <- joined_int %>%
  #calculate length of each interval
  mutate(int_length = int_length(Interval) %>% as_hms()) %>% 
  #group by date and summarize 
  mutate(Date = as.Date(int_end(Interval)), #first, Date and corresponding weekday are calculated
         day = format(Date, format = "%A", locale="English") %>% 
           forcats::fct_inorder()) %>%
  group_by(Id, State, .add = TRUE) %>%
  summarize(tot_intlength = sum(int_length) %>% as_hms()) %>%
  ungroup() %>%
  filter(!is.na(State))

# Normalise it to the total time they participated in the experiment
int_types <- int_types %>%
  left_join(particip_int, by ="Id") %>% #append the column containing total participation hours from the particip_int df
  mutate(per_length = (as.numeric(tot_intlength)/as.numeric(length_par))*100) #convert to numeric as division betwen difftime objects is not supported


#Calculating median time in each state

summary <- int_types %>%
  group_by(State) %>%
  summarise(mean = mean(per_length),
            sd = sd(per_length),
            min = min(per_length),
            max = max(per_length),
            median = median(per_length),
            range = max-min) %>%
  ungroup()

as.factor(int_types$State)

#Plot
int_types$State <- factor(int_types$State, levels = unique(int_types$State)[order(int_types$per_length, decreasing = TRUE)])

states_dist_jitter <- ggplot(data = int_types, aes(x=per_length, y = State, fill = State)) +
  xlim(NA,100) +
  ggdist::stat_halfeye(
    aes(colour = State,
        fill = State),
    adjust = .5,
    justification = -.25,
    point_color = NA,
    interval_color = NA
    ) +
  geom_boxplot(
    aes(color = State),
    width = .2,
    alpha = .2,
    outlier.shape = NA
  ) +
  geom_jitter(
    aes(colour = State),
    fill = "white",
    height = .1,
    alpha = .3
  ) +
  scale_fill_manual(
    values = c("off" = "#16439C", "on" = "palegreen4", "sleep" = "darkgoldenrod2")) +
  scale_color_manual(
    values = c("off" = "#16439C", "on" = "palegreen4", "sleep" = "darkgoldenrod2")) +
  scale_y_discrete(labels = c("on" = "On", "off" = "Off", "sleep" = "Off while\nsleeping")) +
  theme_classic() +
  ggpubr::rremove("ylab") +
  ggpubr::rremove("y.ticks") +
  labs(title = "(Non-)wear time distribution across the week", x = "Percentage of time (%)") +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5, size = 24),
        axis.text.x = element_text(size = 16),
        axis.title = element_text(size = 18),
        axis.text.y = element_text(size = 16))

#Same plot without jitter and boxplot, just with distribution
  states_dist_histo <- ggplot(data = int_types, aes(x=per_length, y = State, fill = State)) +
  xlim(NA,100) +
  ggdist::stat_halfeye(
    aes(colour = State,
        fill = State),
    adjust = .5,
    point_color = NA,
    interval_color = NA
 #   .width = .7
    ) +
  ggdist::stat_dotsinterval(
    side = "bottom",
    scale = .3,
    slab_colour = NA,
    slab_linewidth = NA) +
  scale_fill_manual(
    values = c("off" = "#16439C", "on" = "palegreen4", "sleep" = "darkgoldenrod2")) +
  scale_y_discrete(labels = c("on" = "On", "off" = "Off", "sleep" = "Off while\nsleeping")) +
  theme_classic() +
  ggpubr::rremove("ylab") +
  ggpubr::rremove("y.ticks") +
  labs(title = "(Non-)wear time distribution across the week", x = "Percentage of time (%)") +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5, size = 24),
        axis.text.x = element_text(size = 16),
        axis.title = element_text(size = 18),
        axis.text.y = element_text(size = 16))


```

###Save plot above
```{r}
ggsave(filename = "state_dist_jitter.png",
       plot = states_dist_jitter ,
       width = 8,
       height = 5,
       dpi = 600,
       path= "F:/cyepi/code/outputs")
```

##Perform a sanity check that plot sleep and wake time from sleep diary 
In the plot above, we visualised time spent in each of the non-wear states: off (device not worn), on (device worn) and off for sleep (device not worn during sleep). As a sanity check, the time that the device is not worn during sleep should be similar to the time that the participants reported actually sleeping, as indicated by the sleep diary. For this reason, we follow a similar approach to the code above to visualise the amount of time participants spend asleep or awake according to the sleep diary. 
```{r}
#Locate the sleep diary files
path_sleep <- here("F:/cyepi/data/raw/group/sleepdiary")

# Get the files names from directory
sleepdiary = list.files(path_sleep, pattern="*.csv", full.names = TRUE)

#Using LightLogR, we import the files and label each timestamp as wake or sleep
sleepdiary_df <- LightLogR::import_Statechanges(sleepdiary,
                                     Datetime.format = "dmyHM",
                                     State.colnames = c("sleep", "offset"),
                                     State.encoding = c("sleep", "wake"),
                                     Id.colname = record_id,
                                     sep = ";",
                                     dec = ",",
                                     tz = tz)

#Similar to what was done for the wearlog intervals, we now turn the state changes of the sleep diary to an interval
sleep_int <- sleepdiary_df %>%
  sc2interval() %>%
  filter(!is.na(State))

#Calculate the amount of time spent in each state (either awake or alseep), for each participant across the whole experiment duration
sleep_int <- sleep_int %>%
#calculate length of each interval
  mutate(int_length = int_length(Interval) %>% as_hms()) %>% 
  #group by date and summarize 
  mutate(Date = as.Date(int_end(Interval)), #first, Date and corresponding weekday are calculated
         day = format(Date, format = "%A", locale="English") %>% 
           forcats::fct_inorder()) %>%
  group_by(Id, State, .add = TRUE) %>%
  summarize(tot_intlength = sum(int_length) %>% as_hms()) %>%
  ungroup() %>%
  filter(!is.na(State))


# Normalise it to the total time they participated in the experiment
sleep_int <- sleep_int %>%
  left_join(particip_int, by ="Id") %>% #append the column containing total participation hours from the particip_int df
  #note that particip_int has been calculate earlier and can be reused here 
  mutate(per_length = (as.numeric(tot_intlength)/as.numeric(length_par))*100) #convert to numeric as division betwen difftime objects is not supported

#Turn state into factor
as.factor(sleep_int$State)

#Organise the order of the factor levels to determine what comes first in the plot
sleep_int$State <- factor(sleep_int$State, levels = unique(sleep_int$State)[order(sleep_int$per_length, decreasing = TRUE)])

#Plot
sleep_wake_dist <-
  ggplot(data = sleep_int, aes(x=per_length, y = State, fill = State)) +
  xlim(NA,100) +
  ggdist::stat_halfeye(
    aes(colour = State,
        fill = State),
    adjust = .5,
    justification = -.15,
    point_color = NA,
    interval_color = NA
    ) +
  geom_boxplot(
    aes(color = State),
    width = .2,
    alpha = .2,
    outlier.shape = NA
  ) +
  geom_jitter(
    aes(colour = State),
    fill = "white",
    height = .1,
    alpha = .3
  ) +
  scale_fill_manual(
    values = c("sleep" = "darkgoldenrod2", "wake" = "darkcyan")) +
  scale_color_manual(
    values = c("sleep" = "darkgoldenrod2", "wake" = "darkcyan")) +
  scale_y_discrete(labels = c("sleep" = "Sleep", "wake" = "Wake")) +
  theme_classic() +
  ggpubr::rremove("ylab") +
  ggpubr::rremove("y.ticks") +
  labs(title = "Sleep and wake distribution across the week", x = "Percentage of time (%)") +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5, size = 24),
        axis.text.x = element_text(size = 16),
        axis.title = element_text(size = 18),
        axis.text.y = element_text(size = 16))

##Save plot above
ggsave(filename = "sleep_wake_dist.png",
       plot = sleep_wake_dist ,
       width = 8,
       height = 5,
       dpi = 600,
       path= "F:/cyepi/code/outputs")
```

#Do the same but no distinction between weekday and weekend
```{r}
tot_nonwear <- int_types%>%
  filter(State == "off")

#tot_nonwear$offtime_per <- (tot_nonwear$off_time / (24*7))*100

nonwear_dist_overview <- ggplot(data = tot_nonwear, aes(x = per_length, fill = State))  +
  xlim(NA, 100) +
  ggdist::stat_halfeye(
    aes(colour = State,
        fill = State),
    adjust = .5,
    ) +
  ggdist::stat_dotsinterval(
    side = "bottom",
    scale = .3,
    slab_colour = NA,
    slab_linewidth = NA) +
   scale_fill_manual(values = c("off" = "#16439C")) +
  theme_classic() +
  labs(title = "Non-wear time distribution", x = "Non-wear time (%)") +
  ggpubr::rremove("ylab") +
  ggpubr::rremove("y.ticks") +
  ggpubr::rremove("y.text") +
  theme(plot.title = element_text(hjust = 0.5, size = 24),
        axis.text.x = element_text(size = 16),
        axis.title = element_text(size = 18),
        axis.text.x.top = element_blank(),
        axis.ticks.x.top = element_blank(),
        axis.line.x.top = element_blank(),
        legend.position = "none") +
  scale_x_break(c(15,99.9),
                ticklabels = 100)

ggsave(filename = "nonwear_dist_overview_100.png",
       plot = nonwear_dist_overview ,
       width = 8,
       height = 5,
       dpi = 600,
       path= "F:/cyepi/code/outputs")
```




